{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Importing all modules in cell below."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from typing import Callable, Iterable"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data = np.loadtxt('../support/zipcombo.dat')\n",
    "# data = np.loadtxt('../support/dtrain123.dat')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(9298, 257)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now define functions for splitting the dataset into train/test and input/label."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def split_80_20(data: np.ndarray) -> (np.ndarray, np.ndarray):\n",
    "    \"\"\"\n",
    "    Splits 80% train 20% test\n",
    "\n",
    "    :param data: sequence.\n",
    "    :return: train_data, test_data: np.ndarray, np.ndarray\n",
    "    \"\"\"\n",
    "\n",
    "    n = data.shape[0]\n",
    "    train_size = int(n*0.8)\n",
    "    return data[:train_size], data[train_size:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def split_X_y(data: np.ndarray) -> (np.ndarray, np.ndarray):\n",
    "    \"\"\"\n",
    "    Splits the data into datapoints and labels, X_train matrix and y_train;\n",
    "    :param data: np.ndarray\n",
    "    :return: X_train, y_train: np.ndarray, np.ndarray\n",
    "    \"\"\"\n",
    "\n",
    "    return data[:, 1:], data[:, 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def shuffle_split(data):\n",
    "    # np.random.seed(seed)\n",
    "    shuffled = np.random.permutation(data)\n",
    "    data_train, data_test = split_80_20(shuffled)\n",
    "    X_train, y_train = split_X_y(data_train)\n",
    "    X_test, y_test = split_X_y(data_test)\n",
    "\n",
    "    assert X_train.shape[0] == y_train.size\n",
    "    assert X_test.shape[0] == y_test.size\n",
    "\n",
    "    print(\"Train data set size = %d\" % X_train.shape[0])\n",
    "    print(\"Test data set size = %d\" % X_test.shape[0])\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data set size = 7438\n",
      "Test data set size = 1860\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = shuffle_split(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def display_digit(grayscale):\n",
    "    plt.imshow(np.reshape(grayscale, (16, 16)), cmap='gray')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_digit(X_train[100])\n",
    "print(y_train[100])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us now define the Kernel Perceptron algorithm and kernel functions to be used."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def polynomial_kernel(x_i: np.ndarray, x_t: np.ndarray, d: int):\n",
    "    return np.inner(x_i, x_t) ** d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def gaussian_kernel(x_i: np.ndarray, x_j: np.ndarray, sigma=1):\n",
    "    if x_i.shape[0] != x_j.shape[0]:\n",
    "        raise Exception(\"Cannot apply kernel to vectors of different dimensions: x_i has shape {s1}, x_j has shape {s2}\"\n",
    "                        .format(s1=x_i.shape, s2=x_j.shape))\n",
    "    diff = x_i - x_j\n",
    "    return np.exp(-1 * np.inner(diff, diff) / (2 * sigma**2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "class KernelPerceptron:\n",
    "    def __init__(self, kernel: Callable[[np.ndarray, np.ndarray], float], size: int):\n",
    "        self.kernel = kernel\n",
    "        self.K = None\n",
    "        self.alpha = np.zeros(size)\n",
    "        self.X_train = None\n",
    "\n",
    "    def _get_kernel_matrix(self, X_train: np.ndarray) -> np.ndarray:\n",
    "        K = np.zeros((X_train.shape[0], X_train.shape[0]))\n",
    "\n",
    "        for i in range(0, X_train.shape[0]):\n",
    "            for j in range(i, X_train.shape[0]):\n",
    "                K[i, j] = K[j, i] = self.kernel(X_train[i], X_train[j])\n",
    "\n",
    "        return K\n",
    "\n",
    "    def fit(self, X_train: np.ndarray, y_train: np.ndarray, n_epochs: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Prediction function that populates the alpha parameter, 1 data point at a time;\n",
    "        :param X_train: training data points\n",
    "        :param y_train: training corresponding labels\n",
    "        :param n_epochs: number of times to pass through the data. Alpha contains the learning parameters that get inherited from one epoch to the other\n",
    "        :return: y_preds: the predictions enhanced after N epochs\n",
    "\n",
    "        \"\"\"\n",
    "        if y_train.ndim != 1:\n",
    "            raise Exception('y_train must be a 1-dim np.ndarray. Given y_train with shape {s}'.format(s=y_train.shape))\n",
    "        if X_train.shape[0] != y_train.size:\n",
    "            raise Exception('X_train and y_train must contain equal number of samples. Given X_train with shape {s1} and y_train with shape {s2}'.format(s1=y_train.shape, s2=X_train.shape))\n",
    "\n",
    "        y_preds = np.zeros(X_train.shape[0])\n",
    "        self.X_train = X_train\n",
    "\n",
    "        # Compute kernel matrix which stays constant throughout the algorithm and all epochs\n",
    "        self.K = self._get_kernel_matrix(X_train)\n",
    "\n",
    "        for epoch in range(0, n_epochs):\n",
    "            for t in range(0, X_train.shape[0]):\n",
    "                y_pred = self._predict_single(t)\n",
    "                y_preds[t] = y_pred\n",
    "                if y_pred != y_train[t]:\n",
    "                    self.alpha[t] += y_train[t]\n",
    "        return y_preds\n",
    "\n",
    "    def _predict_single(self, t: int):\n",
    "        \"\"\"\n",
    "        We take a whole row of kernel matrix K because in we want to account for errors in previous epochs.\n",
    "        This is not an issue in the first epoch because all alpha's > t are 0.\n",
    "        :param t: iteration step in the online learning algorithm.\n",
    "        :return: y hat, single predicted value at step t.\n",
    "        \"\"\"\n",
    "        return np.sign(np.inner(self.K[t, :], self.alpha))\n",
    "\n",
    "    def yhat_single(self, K, t: int):\n",
    "        return np.sign(np.inner(K[t, :], self.alpha))\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Prediction function to be used for out-of-sample test data point.\n",
    "        Does not perform online learning (update step).\n",
    "        :param X: test data points.\n",
    "        :return: np.ndarray of predictions for each given test data point.\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        for x_test in X:\n",
    "            sum = 0\n",
    "            for t in range(self.X_train.shape[0]):\n",
    "                # Can improve by using kernel matrix\n",
    "                sum += self.alpha[t] * self.kernel(self.X_train[t], x_test)\n",
    "            predictions.append(np.sign(sum))\n",
    "        return np.array(predictions)\n",
    "\n",
    "\n",
    "# kp = KernelPerceptron(kernel=partial(polynomial_kernel, d=3))\n",
    "# y_insample = kp.fit(X_train_12, y_train_12, n_epochs=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def get_error_percentage_old(y_train, y_insample, y_test, y_outsample):\n",
    "    training_error = 100 * get_num_mistakes(actual=y_train, predicted=y_insample) / y_train.size\n",
    "    test_errors = 100 * get_num_mistakes(actual=y_test, predicted=y_outsample) / y_test.size\n",
    "    print(\"in-sample = % \" + str(training_error))\n",
    "    print(\"out-of-sample = % \" + str(test_errors))\n",
    "    return training_error, test_errors\n",
    "\n",
    "def get_error_percentage(y, y_preds):\n",
    "    error = 100 * get_num_mistakes(actual=y, predicted=y_preds) / y.size\n",
    "    print(\"in-sample = % \" + str(error))\n",
    "    return error\n",
    "\n",
    "def get_num_mistakes(actual: np.ndarray, predicted: np.ndarray) -> int:\n",
    "    # or calculating by checking which alpha values are different than 0? alpha is 0 when the prediction matches\n",
    "    diffs = actual - predicted\n",
    "    n_mistakes = 0\n",
    "    for diff in diffs:\n",
    "        if diff != 0:\n",
    "            n_mistakes += 1\n",
    "    return n_mistakes\n",
    "\n",
    "class KPOneVsAllClassifier:\n",
    "    def __init__(self, kernel, n_classes, d):\n",
    "        self.kernel = kernel\n",
    "        self.n_classes = n_classes # could optimize to remove this var since =k.shape[0]\n",
    "        self.d = d\n",
    "        self.X_train = None\n",
    "        self.Alpha = None\n",
    "        self.K = None\n",
    "\n",
    "    def _get_kernel_matrix(self, X_train: np.ndarray) -> np.ndarray:\n",
    "        ### TODO: Takes a lot of time, we should improve efficiency\n",
    "        # K = np.zeros((X_train.shape[0], X_train.shape[0]))\n",
    "        # for i in range(0, X_train.shape[0]):\n",
    "        #     for j in range(i, X_train.shape[0]):\n",
    "        #         K[i, j] = K[j, i] = self.kernel(X_train[i], X_train[j], d=self.d)\n",
    "        # return K\n",
    "        return np.power(X_train @ X_train.T, self.d)\n",
    "\n",
    "    def sign(self, x: np.ndarray) -> np.ndarray:\n",
    "        return np.where(x <= 0, -1, 1)\n",
    "\n",
    "    def _predict_single_confidence(self, t, y_train):\n",
    "        # Get prediction array P\n",
    "        # preds = (self.Alpha @ self.K)[:, t]\n",
    "        preds = self.Alpha @ self.K[t]\n",
    "\n",
    "        # Get Y_t array of ground truth (duplicate y_t)\n",
    "        y = np.full(self.n_classes, -1)\n",
    "        y[int(y_train[t])] = 1\n",
    "\n",
    "        # penilize\n",
    "        # how should the alpha look like on miss on y=7 ? 1 1 1 1 1 1 1 -1 1 1 (only 7 is penilized?) or -1 -1 ... -1 (everybody is penilized\n",
    "        # should we only penilize the respective perceptron? e.g., if y=7, and perceptron[7]=0, should we penilize just perceptron 7?\n",
    "        self.Alpha[:, t] -= np.heaviside(-(preds * y), 1) * self.sign(preds)\n",
    "        return preds\n",
    "        # for each perceptron\n",
    "        # for cl in range(self.n_classes):\n",
    "        #     # create and save predictions\n",
    "        #     pred = np.inner(self.K[t, :], perceptrons[cl].alpha)\n",
    "        #     confidence[cl] = pred\n",
    "        #\n",
    "        #     y = 1 if y_train[t] == float(cl) else (-1)\n",
    "        #     ## penalize if the prediction wrong\n",
    "        #     if y*pred <= 0:\n",
    "        #         perceptrons[cl].alpha[t] -= self.sign(pred)\n",
    "\n",
    "    def fit(self, X_train, y_train, n_epochs):\n",
    "        y_preds = np.array(np.zeros(X_train.shape[0]))\n",
    "\n",
    "        self.K = self._get_kernel_matrix(X_train)\n",
    "        self.Alpha = np.zeros((self.n_classes, X_train.shape[0]))\n",
    "        self.X_train = X_train\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            # for each point, calculate confidence and make predictions\n",
    "            for t in range(0, X_train.shape[0]):\n",
    "                confidence = self._predict_single_confidence(t, y_train)\n",
    "                # the index with the highest number(confidence) is the prediction\n",
    "                # +1 because the index for confidence in perceptron[1] is 0\n",
    "                y_preds[t] = np.argmax(confidence) + 1\n",
    "        return y_preds\n",
    "\n",
    "    # def _choose_best_ytest(self, yhats):\n",
    "    #     # get the classifiers that predicted positive\n",
    "    #     maxims = np.argwhere(yhats == np.amax(yhats)).flatten() + 1\n",
    "    #     if maxims.shape[0] == 1:\n",
    "    #         # if only 1 classifier predicts positive, take that class\n",
    "    #          return maxims[0]\n",
    "    #     else:\n",
    "    #         # if more than one predicted positive, or all of them negative, choose one randomly\n",
    "    #         return np.random.choice(maxims)\n",
    "\n",
    "    def predict(self, X_test: np.ndarray):\n",
    "        ## for polynomial kernel\n",
    "        self.K_test = np.power(X_train @ X_test.T, self.d)\n",
    "        return np.argmax((self.Alpha @ self.K_test), axis=0)\n",
    "        #\n",
    "        # for t_test in range(X_test.shape[0]):\n",
    "        #     yhats_sums = self.Alpha @ self.K_test[t_test]\n",
    "        #     ypreds[t_test] = self._choose_best_ytest(yhats_sums)\n",
    "        #     yhats_sums = np.array(np.zeros(self.n_classes))\n",
    "        #     for cl in range(self.n_classes):\n",
    "        #         # update\n",
    "        #         sum = np.inner(self.Alpha[:, t])\n",
    "        #         for t in range(self.X_train.shape[0]):\n",
    "        #             sum += self.perceptrons[cl].alpha[t] * self.kernel(self.X_train[t], X_test[t_test], self.d)\n",
    "        #         yhats_sums[cl] = sum\n",
    "        # return ypreds\n",
    "\n",
    "\n",
    "### for in-cell debug\n",
    "# import time\n",
    "#\n",
    "# start = time.time()\n",
    "#\n",
    "# kpova = KPOneVsAllClassifier(polynomial_kernel, n_classes=10, d=3)\n",
    "# kpova.fit(X_train, y_train, n_epochs=50)\n",
    "# y_insample = kpova.predict(X_train)\n",
    "# y_outsample = kpova.predict(X_test)\n",
    "#\n",
    "# end = time.time()\n",
    "#\n",
    "# print(\"took :{t}\".format(t=end-start))\n",
    "#\n",
    "# get_error_percentage(y_train, y_insample, y_test, y_outsample)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took :4.681886434555054\n",
      "in-sample = % 2.030115622479161\n",
      "out-of-sample = % 4.193548387096774\n"
     ]
    },
    {
     "data": {
      "text/plain": "(2.030115622479161, 4.193548387096774)"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "kpova = KPOneVsAllClassifier(polynomial_kernel, n_classes=10, d=3)\n",
    "kpova.fit(X_train, y_train, n_epochs=1)\n",
    "y_insample = kpova.predict(X_train)\n",
    "y_outsample = kpova.predict(X_test)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"took :{t}\".format(t=end-start))\n",
    "\n",
    "get_error_percentage(y_train, y_insample, y_test, y_outsample)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### _Tests_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us test the Kernel Perceptron implementation on a dummy dataset of only digits 1 and 2."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Filter out digit 3 (leave only digit 1 and 2) from dtrain123.dat train and test dataset\n",
    "indxs_digit_3 = np.where(y_train_123 == 3)\n",
    "X_train_12 = np.delete(X_train_123, indxs_digit_3, axis=0)\n",
    "y_train_12 = np.delete(y_train_123, indxs_digit_3)\n",
    "y_train_12[y_train_12 == 1] = -1\n",
    "y_train_12[y_train_12 == 2] = 1\n",
    "\n",
    "indxs_digit_3 = np.where(y_test_123 == 3)\n",
    "X_test_12 = np.delete(X_test_123, indxs_digit_3, axis=0)\n",
    "y_test_12 = np.delete(y_test_123, indxs_digit_3)\n",
    "y_test_12[y_test_12 == 1] = -1\n",
    "y_test_12[y_test_12 == 2] = 1\n",
    "\n",
    "assert X_train_12.shape[0] == y_train_12.size\n",
    "assert X_test_12.shape[0] == y_test_12.size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample = % 0.0\n",
      "out-of-sample = % 1.8518518518518519\n"
     ]
    }
   ],
   "source": [
    "# Test fitting and in-sample predictions\n",
    "kp = KernelPerceptron(kernel=partial(polynomial_kernel, d=5), size=X_train_12.shape[0])\n",
    "y_insample = kp.fit(X_train_12, y_train_12, n_epochs=2)\n",
    "# Test out-of-sample predictions\n",
    "y_outsample = kp.predict(X_test_12) # all predictions of test sample in y_outsample\n",
    "print(\"in-sample = % \" + str(100 * get_num_mistakes(actual=y_train_12, predicted=y_insample) / y_train_12.size))\n",
    "print(\"out-of-sample = % \" + str(100 * get_num_mistakes(actual=y_test_12, predicted=y_outsample) / y_test_12.size))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "KernelPerceptron.__init__() missing 1 required positional argument: 'size'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[69], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m## Test the kernel matrix\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m kp_test \u001B[38;5;241m=\u001B[39m \u001B[43mKernelPerceptron\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkernel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpartial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpolynomial_kernel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43md\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m kernel_matrix \u001B[38;5;241m=\u001B[39m kp_test\u001B[38;5;241m.\u001B[39m_get_kernel_matrix(X_train_12)\n\u001B[0;32m      4\u001B[0m polynomial_kernel(X_train_12[\u001B[38;5;241m0\u001B[39m], X_train_12[\u001B[38;5;241m0\u001B[39m], d\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m) \u001B[38;5;241m==\u001B[39m kernel_matrix[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[1;31mTypeError\u001B[0m: KernelPerceptron.__init__() missing 1 required positional argument: 'size'"
     ]
    }
   ],
   "source": [
    "## Test the kernel matrix\n",
    "kp_test = KernelPerceptron(kernel=partial(polynomial_kernel, d=3))\n",
    "kernel_matrix = kp_test._get_kernel_matrix(X_train_12)\n",
    "polynomial_kernel(X_train_12[0], X_train_12[0], d=3) == kernel_matrix[0][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# *_Part 1_*\n",
    "\n",
    "### 1. *Basic results*\n",
    "- for $d=1, ... ,7$ perform 20 runs\n",
    "- split $zipcombo$ 80-20\n",
    "- report MSE and STD\n",
    "- yield a 2x7 table that has on each cell $mean+-std$\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=1 on run 0\n",
      "in-sample = % 8.26835170744824\n",
      "in-sample = % 8.978494623655914\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=1 on run 1\n",
      "in-sample = % 8.765797257327238\n",
      "in-sample = % 10.10752688172043\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=1 on run 2\n",
      "in-sample = % 13.310029577843506\n",
      "in-sample = % 14.731182795698924\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=1 on run 3\n",
      "in-sample = % 9.854799677332617\n",
      "in-sample = % 11.075268817204302\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=1 on run 4\n",
      "in-sample = % 10.110244689432642\n",
      "in-sample = % 10.806451612903226\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=1 on run 5\n",
      "in-sample = % 10.217800484001076\n",
      "in-sample = % 11.129032258064516\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=1 on run 6\n",
      "in-sample = % 8.053240118311374\n",
      "in-sample = % 9.731182795698924\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=1 on run 7\n",
      "in-sample = % 11.011024468943264\n",
      "in-sample = % 11.182795698924732\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=1 on run 8\n",
      "in-sample = % 15.730034955633235\n",
      "in-sample = % 15.806451612903226\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=1 on run 9\n",
      "in-sample = % 8.295240656090346\n",
      "in-sample = % 9.408602150537634\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=1 on run 10\n",
      "in-sample = % 9.061575692390427\n",
      "in-sample = % 10.913978494623656\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=1 on run 11\n",
      "in-sample = % 8.577574616832482\n",
      "in-sample = % 9.89247311827957\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=1 on run 12\n",
      "in-sample = % 12.436138746974994\n",
      "in-sample = % 14.56989247311828\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=1 on run 13\n",
      "in-sample = % 8.712019360043023\n",
      "in-sample = % 10.376344086021506\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=1 on run 14\n",
      "in-sample = % 9.317020704490455\n",
      "in-sample = % 11.559139784946236\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=1 on run 15\n",
      "in-sample = % 9.653132562516806\n",
      "in-sample = % 10.053763440860216\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=1 on run 16\n",
      "in-sample = % 9.989244420543157\n",
      "in-sample = % 11.397849462365592\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=1 on run 17\n",
      "in-sample = % 9.088464641032536\n",
      "in-sample = % 10.86021505376344\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=1 on run 18\n",
      "in-sample = % 9.357354127453616\n",
      "in-sample = % 9.56989247311828\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=1 on run 19\n",
      "in-sample = % 13.377251949448777\n",
      "in-sample = % 14.89247311827957\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=2 on run 0\n",
      "in-sample = % 3.8047862328582953\n",
      "in-sample = % 5.752688172043011\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=2 on run 1\n",
      "in-sample = % 3.5627856950793224\n",
      "in-sample = % 5.806451612903226\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=2 on run 2\n",
      "in-sample = % 3.3073406829792953\n",
      "in-sample = % 5.161290322580645\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=2 on run 3\n",
      "in-sample = % 3.8451196558214575\n",
      "in-sample = % 5.21505376344086\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=2 on run 4\n",
      "in-sample = % 3.3342296316214037\n",
      "in-sample = % 4.516129032258065\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=2 on run 5\n",
      "in-sample = % 4.006453347674106\n",
      "in-sample = % 6.182795698924731\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=2 on run 6\n",
      "in-sample = % 3.0250067222371606\n",
      "in-sample = % 4.78494623655914\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=2 on run 7\n",
      "in-sample = % 4.477009948910998\n",
      "in-sample = % 6.397849462365591\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=2 on run 8\n",
      "in-sample = % 4.974455498789998\n",
      "in-sample = % 7.688172043010753\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=2 on run 9\n",
      "in-sample = % 3.45522990051089\n",
      "in-sample = % 6.397849462365591\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=2 on run 10\n",
      "in-sample = % 3.764452809895133\n",
      "in-sample = % 5.376344086021505\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=2 on run 11\n",
      "in-sample = % 3.8316751815004033\n",
      "in-sample = % 6.129032258064516\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=2 on run 12\n",
      "in-sample = % 3.0518956708792686\n",
      "in-sample = % 5.161290322580645\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=2 on run 13\n",
      "in-sample = % 3.6165635923635384\n",
      "in-sample = % 4.78494623655914\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=2 on run 14\n",
      "in-sample = % 2.82333960742135\n",
      "in-sample = % 5.376344086021505\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=2 on run 15\n",
      "in-sample = % 3.9930088733530518\n",
      "in-sample = % 6.451612903225806\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=2 on run 16\n",
      "in-sample = % 3.3207851573003495\n",
      "in-sample = % 4.946236559139785\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=2 on run 17\n",
      "in-sample = % 3.710674912610917\n",
      "in-sample = % 5.645161290322581\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=2 on run 18\n",
      "in-sample = % 2.904006453347674\n",
      "in-sample = % 4.78494623655914\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=2 on run 19\n",
      "in-sample = % 3.1997848884108633\n",
      "in-sample = % 4.89247311827957\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=3 on run 0\n",
      "in-sample = % 1.76122613605808\n",
      "in-sample = % 4.301075268817204\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=3 on run 1\n",
      "in-sample = % 1.720892713094918\n",
      "in-sample = % 4.301075268817204\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=3 on run 2\n",
      "in-sample = % 2.863673030384512\n",
      "in-sample = % 5.645161290322581\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=3 on run 3\n",
      "in-sample = % 2.1107824684054854\n",
      "in-sample = % 3.763440860215054\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=3 on run 4\n",
      "in-sample = % 1.9763377251949448\n",
      "in-sample = % 4.89247311827957\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=3 on run 5\n",
      "in-sample = % 2.541005646679215\n",
      "in-sample = % 4.731182795698925\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=3 on run 6\n",
      "in-sample = % 2.1107824684054854\n",
      "in-sample = % 5.0\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=3 on run 7\n",
      "in-sample = % 2.003226673837053\n",
      "in-sample = % 5.161290322580645\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=3 on run 8\n",
      "in-sample = % 1.3578919064264587\n",
      "in-sample = % 4.89247311827957\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=3 on run 9\n",
      "in-sample = % 1.8015595590212423\n",
      "in-sample = % 3.924731182795699\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=3 on run 10\n",
      "in-sample = % 2.7695617101371335\n",
      "in-sample = % 5.10752688172043\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=3 on run 11\n",
      "in-sample = % 2.6216724926055393\n",
      "in-sample = % 5.860215053763441\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=3 on run 12\n",
      "in-sample = % 1.9628932508738908\n",
      "in-sample = % 5.053763440860215\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=3 on run 13\n",
      "in-sample = % 2.339338531863404\n",
      "in-sample = % 5.161290322580645\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=3 on run 14\n",
      "in-sample = % 1.7074482387738639\n",
      "in-sample = % 4.247311827956989\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=3 on run 15\n",
      "in-sample = % 1.2906695348211885\n",
      "in-sample = % 4.139784946236559\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=3 on run 16\n",
      "in-sample = % 1.6402258671685936\n",
      "in-sample = % 4.301075268817204\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=3 on run 17\n",
      "in-sample = % 1.9763377251949448\n",
      "in-sample = % 4.89247311827957\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=3 on run 18\n",
      "in-sample = % 2.057004571121269\n",
      "in-sample = % 4.301075268817204\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=3 on run 19\n",
      "in-sample = % 1.9225598279107288\n",
      "in-sample = % 4.354838709677419\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=4 on run 0\n",
      "in-sample = % 1.19655821457381\n",
      "in-sample = % 3.4408602150537635\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=4 on run 1\n",
      "in-sample = % 1.6805592901317559\n",
      "in-sample = % 4.193548387096774\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=4 on run 2\n",
      "in-sample = % 1.5461145469212154\n",
      "in-sample = % 4.193548387096774\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=4 on run 3\n",
      "in-sample = % 1.4654477009948912\n",
      "in-sample = % 4.56989247311828\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=4 on run 4\n",
      "in-sample = % 2.1242269427265392\n",
      "in-sample = % 5.32258064516129\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=4 on run 5\n",
      "in-sample = % 1.156224791610648\n",
      "in-sample = % 3.010752688172043\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=4 on run 6\n",
      "in-sample = % 1.747781661737026\n",
      "in-sample = % 4.516129032258065\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=4 on run 7\n",
      "in-sample = % 1.1293358429685398\n",
      "in-sample = % 3.3333333333333335\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=4 on run 8\n",
      "in-sample = % 1.4788921753159452\n",
      "in-sample = % 4.731182795698925\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=4 on run 9\n",
      "in-sample = % 1.411669803710675\n",
      "in-sample = % 3.763440860215054\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=4 on run 10\n",
      "in-sample = % 1.6133369185264856\n",
      "in-sample = % 4.301075268817204\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=4 on run 11\n",
      "in-sample = % 2.016671148158107\n",
      "in-sample = % 4.67741935483871\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=4 on run 12\n",
      "in-sample = % 1.1293358429685398\n",
      "in-sample = % 4.408602150537634\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=4 on run 13\n",
      "in-sample = % 1.2234471632159183\n",
      "in-sample = % 4.032258064516129\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=4 on run 14\n",
      "in-sample = % 1.5326700726001614\n",
      "in-sample = % 4.56989247311828\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=4 on run 15\n",
      "in-sample = % 1.3041140091422425\n",
      "in-sample = % 4.193548387096774\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=4 on run 16\n",
      "in-sample = % 1.8822264049475665\n",
      "in-sample = % 4.354838709677419\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=4 on run 17\n",
      "in-sample = % 2.043560096800215\n",
      "in-sample = % 5.10752688172043\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=4 on run 18\n",
      "in-sample = % 1.19655821457381\n",
      "in-sample = % 3.817204301075269\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=4 on run 19\n",
      "in-sample = % 1.3444474321054047\n",
      "in-sample = % 4.086021505376344\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=5 on run 0\n",
      "in-sample = % 1.0755579456843238\n",
      "in-sample = % 3.924731182795699\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=5 on run 1\n",
      "in-sample = % 1.4654477009948912\n",
      "in-sample = % 4.731182795698925\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=5 on run 2\n",
      "in-sample = % 1.8553374563054585\n",
      "in-sample = % 4.78494623655914\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=5 on run 3\n",
      "in-sample = % 1.3041140091422425\n",
      "in-sample = % 4.354838709677419\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=5 on run 4\n",
      "in-sample = % 1.19655821457381\n",
      "in-sample = % 4.139784946236559\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=5 on run 5\n",
      "in-sample = % 1.2368916375369723\n",
      "in-sample = % 3.010752688172043\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=5 on run 6\n",
      "in-sample = % 1.169669265931702\n",
      "in-sample = % 4.516129032258065\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=5 on run 7\n",
      "in-sample = % 0.9545576767948373\n",
      "in-sample = % 3.4408602150537635\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=5 on run 8\n",
      "in-sample = % 1.2503361118580263\n",
      "in-sample = % 3.978494623655914\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=5 on run 9\n",
      "in-sample = % 0.9948910997579995\n",
      "in-sample = % 4.623655913978495\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=5 on run 10\n",
      "in-sample = % 0.9680021511158914\n",
      "in-sample = % 4.247311827956989\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=5 on run 11\n",
      "in-sample = % 1.411669803710675\n",
      "in-sample = % 3.6021505376344085\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=5 on run 12\n",
      "in-sample = % 0.7528905619790266\n",
      "in-sample = % 3.763440860215054\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=5 on run 13\n",
      "in-sample = % 0.9545576767948373\n",
      "in-sample = % 4.354838709677419\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=5 on run 14\n",
      "in-sample = % 1.3041140091422425\n",
      "in-sample = % 3.6021505376344085\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=5 on run 15\n",
      "in-sample = % 2.245227211616026\n",
      "in-sample = % 4.408602150537634\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=5 on run 16\n",
      "in-sample = % 1.411669803710675\n",
      "in-sample = % 3.978494623655914\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=5 on run 17\n",
      "in-sample = % 1.2234471632159183\n",
      "in-sample = % 3.6559139784946235\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=5 on run 18\n",
      "in-sample = % 1.2772250605001345\n",
      "in-sample = % 4.516129032258065\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=5 on run 19\n",
      "in-sample = % 0.9680021511158914\n",
      "in-sample = % 4.408602150537634\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=6 on run 0\n",
      "in-sample = % 0.8066684592632428\n",
      "in-sample = % 4.731182795698925\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=6 on run 1\n",
      "in-sample = % 0.887335305189567\n",
      "in-sample = % 4.139784946236559\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=6 on run 2\n",
      "in-sample = % 1.3578919064264587\n",
      "in-sample = % 3.4408602150537635\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=6 on run 3\n",
      "in-sample = % 0.9680021511158914\n",
      "in-sample = % 4.032258064516129\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=6 on run 4\n",
      "in-sample = % 1.4923366496369992\n",
      "in-sample = % 4.193548387096774\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=6 on run 5\n",
      "in-sample = % 1.6133369185264856\n",
      "in-sample = % 3.817204301075269\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=6 on run 6\n",
      "in-sample = % 0.7394460876579726\n",
      "in-sample = % 4.086021505376344\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=6 on run 7\n",
      "in-sample = % 1.1024468943264318\n",
      "in-sample = % 4.032258064516129\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=6 on run 8\n",
      "in-sample = % 1.2637805861790803\n",
      "in-sample = % 4.56989247311828\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=6 on run 9\n",
      "in-sample = % 1.1158913686474858\n",
      "in-sample = % 3.172043010752688\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=6 on run 10\n",
      "in-sample = % 1.0890024200053778\n",
      "in-sample = % 3.4408602150537635\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=6 on run 11\n",
      "in-sample = % 1.0621134713632696\n",
      "in-sample = % 4.193548387096774\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=6 on run 12\n",
      "in-sample = % 0.9680021511158914\n",
      "in-sample = % 4.032258064516129\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=6 on run 13\n",
      "in-sample = % 0.9948910997579995\n",
      "in-sample = % 4.086021505376344\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=6 on run 14\n",
      "in-sample = % 1.3444474321054047\n",
      "in-sample = % 3.4946236559139785\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=6 on run 15\n",
      "in-sample = % 1.6940037644528099\n",
      "in-sample = % 4.301075268817204\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=6 on run 16\n",
      "in-sample = % 1.0486689970422156\n",
      "in-sample = % 3.870967741935484\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=6 on run 17\n",
      "in-sample = % 1.1024468943264318\n",
      "in-sample = % 3.870967741935484\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=6 on run 18\n",
      "in-sample = % 0.860446356547459\n",
      "in-sample = % 3.4946236559139785\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=6 on run 19\n",
      "in-sample = % 0.860446356547459\n",
      "in-sample = % 3.7096774193548385\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=7 on run 0\n",
      "in-sample = % 1.0217800484001076\n",
      "in-sample = % 4.139784946236559\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=7 on run 1\n",
      "in-sample = % 1.5864479698843774\n",
      "in-sample = % 4.301075268817204\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=7 on run 2\n",
      "in-sample = % 1.1158913686474858\n",
      "in-sample = % 3.3870967741935485\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=7 on run 3\n",
      "in-sample = % 1.169669265931702\n",
      "in-sample = % 4.516129032258065\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=7 on run 4\n",
      "in-sample = % 1.0083355740790536\n",
      "in-sample = % 4.193548387096774\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=7 on run 5\n",
      "in-sample = % 1.0755579456843238\n",
      "in-sample = % 3.763440860215054\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=7 on run 6\n",
      "in-sample = % 0.8470018822264049\n",
      "in-sample = % 3.924731182795699\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=7 on run 7\n",
      "in-sample = % 0.9007797795106212\n",
      "in-sample = % 2.956989247311828\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=7 on run 8\n",
      "in-sample = % 0.9007797795106212\n",
      "in-sample = % 4.354838709677419\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=7 on run 9\n",
      "in-sample = % 1.1158913686474858\n",
      "in-sample = % 3.924731182795699\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=7 on run 10\n",
      "in-sample = % 1.0083355740790536\n",
      "in-sample = % 3.6559139784946235\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=7 on run 11\n",
      "in-sample = % 1.2637805861790803\n",
      "in-sample = % 3.6559139784946235\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=7 on run 12\n",
      "in-sample = % 2.1645603656897014\n",
      "in-sample = % 5.860215053763441\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=7 on run 13\n",
      "in-sample = % 1.183113740252756\n",
      "in-sample = % 4.086021505376344\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=7 on run 14\n",
      "in-sample = % 0.9680021511158914\n",
      "in-sample = % 3.5483870967741935\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=7 on run 15\n",
      "in-sample = % 1.411669803710675\n",
      "in-sample = % 4.623655913978495\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=7 on run 16\n",
      "in-sample = % 0.8201129335842968\n",
      "in-sample = % 3.225806451612903\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=7 on run 17\n",
      "in-sample = % 1.1293358429685398\n",
      "in-sample = % 3.3870967741935485\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=7 on run 18\n",
      "in-sample = % 1.2100026888948643\n",
      "in-sample = % 3.7096774193548385\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "d=7 on run 19\n",
      "in-sample = % 1.0217800484001076\n",
      "in-sample = % 3.4408602150537635\n",
      "took 682.85400557518\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "means_train = []\n",
    "means_test = []\n",
    "stds_train = []\n",
    "stds_test = []\n",
    "\n",
    "start=time.time()\n",
    "for d in range(1, 8):\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "    for run in range(20):\n",
    "        X_train, y_train, X_test, y_test = shuffle_split(data)\n",
    "\n",
    "        kpova = KPOneVsAllClassifier(polynomial_kernel, n_classes=10, d=d)\n",
    "\n",
    "        #train\n",
    "        kpova.fit(X_train, y_train, n_epochs=1)\n",
    "        y_insample = kpova.predict(X_train)\n",
    "        #test\n",
    "        y_outsample = kpova.predict(X_test)\n",
    "\n",
    "        print('\\nd=' + str(d) + ' on run ' + str(run))\n",
    "        train_errors.append(get_error_percentage(y_train, y_insample))\n",
    "        test_errors.append(get_error_percentage(y_test, y_outsample))\n",
    "    means_train.append(np.mean(train_errors))\n",
    "    means_test.append(np.mean(test_errors))\n",
    "    stds_train.append(np.std(train_errors))\n",
    "    stds_test.append(np.std(test_errors))\n",
    "end = time.time()\n",
    "\n",
    "print('took {t}'.format(t=end-start))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "table_1a = pd.DataFrame({\n",
    "    'mean train': [str(f'{x:.3f}') + u\"\\u00B1\" + str(f'{y:.3f}') for (x, y) in zip(means_train, stds_train)],\n",
    "    'mean test': [str(f'{x:.3f}') + u\"\\u00B1\" + str(f'{y:.3f}') for (x, y) in zip(means_test, stds_test)],\n",
    "})\n",
    "\n",
    "display(table_1a)\n",
    "table_1a.style.to_latex('table_1a.tex')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### _But firstly we need to find how many epochs to train_\n",
    "#### *i.e. A discussion of any parameters of your method which were not cross-validated over.*\n",
    "\n",
    "I ran the basic results algorithm on all $d$s only with 1 epoch in order to observe the \"best\" $d$ for 1 epoch on this dataset and get an intuition.\n",
    "\n",
    "Now I will create a graph that shows the errors for each number of epochs, setting $d=[5, 7]$, plotting the average errors observed per epoch.\n",
    "In order to offset the risk of being biased on a specific order of training datapoints, we will shuffle and split the dataset 20 times and average those per epoch. Each time an epoch analysis(1-15), a new classifier is defined for each nr of epochs, to show the progress individually.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "D = 5\n",
      "\n",
      "   RUN 0\n",
      "Train data set size = 7438\n",
      "Test data set size = 1860\n",
      "\n",
      "           EPOCH 1\n",
      "in-sample = % 1.4923366496369992\n",
      "in-sample = % 3.817204301075269\n",
      "\n",
      "           EPOCH 2\n",
      "in-sample = % 0.5243344985211078\n",
      "in-sample = % 3.3870967741935485\n",
      "\n",
      "           EPOCH 3\n",
      "in-sample = % 0.26888948642108096\n",
      "in-sample = % 2.903225806451613\n",
      "\n",
      "           EPOCH 4\n",
      "in-sample = % 0.1478892175315945\n",
      "in-sample = % 2.849462365591398\n",
      "\n",
      "           EPOCH 5\n",
      "in-sample = % 0.04033342296316214\n",
      "in-sample = % 2.795698924731183\n",
      "\n",
      "           EPOCH 6\n",
      "in-sample = % 0.026888948642108095\n",
      "in-sample = % 2.6344086021505375\n",
      "\n",
      "           EPOCH 7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[25], line 19\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m#train\u001B[39;00m\n\u001B[0;32m     18\u001B[0m kpova\u001B[38;5;241m.\u001B[39mfit(X_train, y_train, n_epochs\u001B[38;5;241m=\u001B[39mn_epochs)\n\u001B[1;32m---> 19\u001B[0m y_insample \u001B[38;5;241m=\u001B[39m \u001B[43mkpova\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m#test\u001B[39;00m\n\u001B[0;32m     21\u001B[0m y_outsample \u001B[38;5;241m=\u001B[39m kpova\u001B[38;5;241m.\u001B[39mpredict(X_test)\n",
      "Cell \u001B[1;32mIn[15], line 96\u001B[0m, in \u001B[0;36mKPOneVsAllClassifier.predict\u001B[1;34m(self, X_test)\u001B[0m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X_test: np\u001B[38;5;241m.\u001B[39mndarray):\n\u001B[0;32m     95\u001B[0m     \u001B[38;5;66;03m## for polynomial kernel\u001B[39;00m\n\u001B[1;32m---> 96\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mK_test \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpower\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m@\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mX_test\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43md\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     97\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39margmax((\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mAlpha \u001B[38;5;241m@\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mK_test), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "errors_per_d = []\n",
    "\n",
    "for d in range(5, 8):\n",
    "    print('\\nD = {d}'.format(d=d))\n",
    "    epoch_train_errors = np.array(np.zeros((20, 15))) # size 20, 15\n",
    "    epoch_test_errors = np.array(np.zeros((20, 15))) # size 20, 15\n",
    "\n",
    "    for run in range(20):\n",
    "        print('\\n   RUN {r}'.format(r=run))\n",
    "        X_train, y_train, X_test, y_test = shuffle_split(data)\n",
    "\n",
    "        train_errors = np.array(np.zeros(15)) # size 15\n",
    "        test_errors = np.array(np.zeros(15)) #size 15\n",
    "        for n_epochs in range(1, 15):\n",
    "            print('\\n           EPOCH {e}'.format(e=n_epochs))\n",
    "            kpova = KPOneVsAllClassifier(polynomial_kernel, n_classes=10, d=d)\n",
    "            #train\n",
    "            kpova.fit(X_train, y_train, n_epochs=n_epochs)\n",
    "            y_insample = kpova.predict(X_train)\n",
    "            #test\n",
    "            y_outsample = kpova.predict(X_test)\n",
    "\n",
    "            train_errors[n_epochs-1] = (get_error_percentage(y_train, y_insample))\n",
    "            test_errors[n_epochs-1] = (get_error_percentage(y_test, y_outsample))\n",
    "        epoch_train_errors[run] = train_errors\n",
    "        epoch_test_errors[run] = test_errors\n",
    "    # take the mean of 20 runs for every n_epoch = per columns\n",
    "    errors_per_d.append((epoch_train_errors.mean(axis=0), epoch_test_errors.mean(axis=0)))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for errors_d in errors_per_d:\n",
    "    train_errors, test_errors = errors_d\n",
    "\n",
    "    x = [epoch for epoch in range(1, 15)]\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.title('Errors per epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error%')\n",
    "    plt.plot(x, train_errors, color = \"red\", linewidth = 1.5, linestyle = \"-.\", label = \"train errors\")\n",
    "    plt.plot(x, test_errors, marker = '+', linestyle = '-', label = 'test_errors')\n",
    "    plt.legend(loc = \"upper left\")\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. _Cross validation_\n",
    "- perform 20 runs\n",
    "- shuffle and split data 80-20\n",
    "- select \"best\" parameter $d*$ using 5-fold cross-validation on the 80% training data\n",
    "- retrain on full 80% training using $d*$\n",
    "- record the test errors for 20%\n",
    "- findings: 20 $d*$ and 20 test errors\n",
    "- output: mean_test_error$\\pm$std, mean_$d*\\pm$std"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def cross_validation(X, y, n_folds):\n",
    "    fold_size = X.shape[0] // n_folds\n",
    "\n",
    "    split_idxs = [i * fold_size - 1 for i in range(1, 5)]\n",
    "    X_folds_list = np.split(X, indices_or_sections=split_idxs)\n",
    "    y_folds_list = np.split(y, indices_or_sections=split_idxs)\n",
    "    assert len(X_folds_list) == len(y_folds_list) == n_folds\n",
    "\n",
    "    errors_d = []\n",
    "    for d in range(1, 8):\n",
    "        local_errors = []\n",
    "        for i in range(n_folds):\n",
    "            # Create a training and test folds from given data\n",
    "            X_train_fold = np.vstack(([X_folds_list[k] for k in range(0, n_folds) if k != i]))\n",
    "            y_train_fold = np.concatenate([y_folds_list[k] for k in range(0, n_folds) if k != i], axis=0)\n",
    "            X_validation_fold = X_folds_list[i]\n",
    "            y_validation_fold = y_folds_list[i]\n",
    "\n",
    "            kp = KPOneVsAllClassifier(polynomial_kernel, n_classes=10, d=d)\n",
    "            kp.fit(X_train_fold, y_train_fold)\n",
    "            y_preds = kp.predict(X_validation_fold)\n",
    "            local_errors.append(get_error_percentage(y_validation_fold, y_preds))\n",
    "\n",
    "        errors_d.append(local_errors)\n",
    "\n",
    "    # errors[index + 1] = d, where d==index\n",
    "    np.argmax(np.mean(errors_d, axis=1))\n",
    "    return best_d\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "KPOneVsAllClassifier.fit() missing 1 required positional argument: 'n_epochs'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[29], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m X_train, y_train \u001B[38;5;241m=\u001B[39m split_X_y(train_data)\n\u001B[0;32m      8\u001B[0m X_test, y_test \u001B[38;5;241m=\u001B[39m split_X_y(test_data)\n\u001B[1;32m---> 10\u001B[0m best_d \u001B[38;5;241m=\u001B[39m \u001B[43mcross_validation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m kpova \u001B[38;5;241m=\u001B[39m KPOneVsAllClassifier(polynomial_kernel, n_classes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, d\u001B[38;5;241m=\u001B[39mbest_d)\n\u001B[0;32m     13\u001B[0m kpova\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n",
      "Cell \u001B[1;32mIn[28], line 20\u001B[0m, in \u001B[0;36mcross_validation\u001B[1;34m(X, y, n_folds)\u001B[0m\n\u001B[0;32m     17\u001B[0m y_validation_fold \u001B[38;5;241m=\u001B[39m y_folds_list[i]\n\u001B[0;32m     19\u001B[0m kp \u001B[38;5;241m=\u001B[39m KPOneVsAllClassifier(polynomial_kernel, n_classes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, d\u001B[38;5;241m=\u001B[39md)\n\u001B[1;32m---> 20\u001B[0m \u001B[43mkp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_fold\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train_fold\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m y_preds \u001B[38;5;241m=\u001B[39m kp\u001B[38;5;241m.\u001B[39mpredict(X_validation_fold)\n\u001B[0;32m     22\u001B[0m local_errors\u001B[38;5;241m.\u001B[39mappend(get_error_percentage(y_validation_fold, y_preds))\n",
      "\u001B[1;31mTypeError\u001B[0m: KPOneVsAllClassifier.fit() missing 1 required positional argument: 'n_epochs'"
     ]
    }
   ],
   "source": [
    "best_ds = []\n",
    "test_errors = []\n",
    "\n",
    "for runs in range(2):\n",
    "    shuffled = np.random.permutation(data)\n",
    "    train_data, test_data = split_80_20(shuffled)\n",
    "    X_train, y_train = split_X_y(train_data)\n",
    "    X_test, y_test = split_X_y(test_data)\n",
    "\n",
    "    best_d = cross_validation(X_train, y_train, 5)\n",
    "\n",
    "    kpova = KPOneVsAllClassifier(polynomial_kernel, n_classes=10, d=best_d)\n",
    "    kpova.fit(X_train, y_train)\n",
    "    y_outsample = kpova.predict(X_test)\n",
    "    test_error = get_error_percentage(y_test, y_outsample)\n",
    "\n",
    "    best_ds.append(best_d)\n",
    "    test_errors.append(test_error)\n",
    "\n",
    "str(f'{np.mean(best_ds):.3f}') + u\"\\u00B1\" + str(f'{np.std(best_ds):.3f}')\n",
    "str(f'{np.mean(test_errors):.3f}') + u\"\\u00B1\" + str(f'{np.std(test_errors):.3f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}