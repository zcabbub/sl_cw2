{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Importing all modules in cell below."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from typing import Callable, Iterable"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load dummy 1-2-3 digit dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# data = np.loadtxt('../support/zipcombo.dat')\n",
    "data_123 = np.loadtxt('../support/dtrain123.dat')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(329, 257)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_123.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now define functions for splitting the dataset into train/test and input/label."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def split_80_20(data: np.ndarray, seed: int) -> (np.ndarray, np.ndarray):\n",
    "    \"\"\"\n",
    "    Splits 80% train 20% test\n",
    "\n",
    "    :param data: sequence.\n",
    "    :param seed: Random seed used to shuffle given data.\n",
    "    :return: train_data, test_data: np.ndarray, np.ndarray\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    n = data.shape[0]\n",
    "    shuffle = np.random.permutation(data)\n",
    "    train_size = int(n*0.8)\n",
    "    return shuffle[:train_size], shuffle[train_size:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def split_X_y(data: np.ndarray) -> (np.ndarray, np.ndarray):\n",
    "    \"\"\"\n",
    "    Splits the data into datapoints and labels, X_train matrix and y_train;\n",
    "    :param data: np.ndarray\n",
    "    :return: X_train, y_train: np.ndarray, np.ndarray\n",
    "    \"\"\"\n",
    "\n",
    "    return data[:, 1:], data[:, 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data set size = 263\n",
      "Test data set size = 66\n"
     ]
    },
    {
     "data": {
      "text/plain": "(2.0,\n array([-1.   , -1.   , -1.   , -1.   , -0.723,  0.203,  0.843,  1.   ,\n         0.556, -0.415, -1.   , -1.   , -1.   , -1.   , -1.   , -1.   ,\n        -1.   , -1.   , -1.   , -0.503,  0.885,  1.   ,  0.847,  0.878,\n         1.   ,  0.966,  0.   , -1.   , -1.   , -1.   , -1.   , -1.   ,\n        -1.   , -1.   , -0.499,  0.91 ,  0.752, -0.201, -0.916, -0.866,\n        -0.312,  0.869,  0.952, -0.495, -1.   , -1.   , -1.   , -1.   ,\n        -1.   , -0.809,  0.921,  0.29 , -0.973, -1.   , -1.   , -1.   ,\n        -1.   , -0.194,  1.   ,  0.275, -1.   , -1.   , -1.   , -1.   ,\n        -1.   , -0.906,  0.119, -0.853, -1.   , -1.   , -1.   , -1.   ,\n        -1.   , -0.94 ,  1.   ,  0.736, -1.   , -1.   , -1.   , -1.   ,\n        -1.   , -1.   , -1.   , -1.   , -1.   , -1.   , -1.   , -1.   ,\n        -1.   , -0.767,  1.   ,  0.711, -1.   , -1.   , -1.   , -1.   ,\n        -1.   , -1.   , -1.   , -1.   , -1.   , -1.   , -1.   , -1.   ,\n        -1.   , -0.345,  1.   ,  0.142, -1.   , -1.   , -1.   , -1.   ,\n        -1.   , -1.   , -1.   , -1.   , -1.   , -1.   , -1.   , -1.   ,\n        -1.   ,  0.288,  0.998, -0.343, -1.   , -1.   , -1.   , -1.   ,\n        -1.   , -1.   , -1.   , -1.   , -1.   , -1.   , -1.   , -1.   ,\n        -0.599,  0.924,  0.619, -1.   , -1.   , -1.   , -1.   , -1.   ,\n        -1.   , -1.   , -1.   , -1.   , -1.   , -1.   , -1.   , -0.844,\n         0.629,  0.937, -0.65 , -1.   , -1.   , -1.   , -1.   , -1.   ,\n        -1.   , -1.   , -1.   , -1.   , -1.   , -1.   , -0.637,  0.499,\n         1.   , -0.275, -1.   , -1.   , -1.   , -1.   , -1.   , -1.   ,\n        -1.   , -1.   , -1.   , -1.   , -0.704,  0.372,  0.988,  0.913,\n        -0.39 , -0.992, -1.   , -1.   , -1.   , -1.   , -1.   , -1.   ,\n        -1.   , -1.   , -1.   ,  0.107,  0.949,  1.   ,  0.537, -0.68 ,\n        -1.   , -1.   , -1.   , -1.   , -0.89 , -0.491, -0.929, -1.   ,\n        -1.   , -1.   , -0.482,  0.999,  1.   , -0.041, -0.814, -0.867,\n        -0.661, -0.396, -0.05 ,  0.443,  0.973,  0.774, -0.853, -1.   ,\n        -1.   , -1.   , -0.785,  0.731,  1.   ,  1.   ,  0.903,  0.876,\n         1.   ,  1.   ,  0.834,  0.35 ,  0.004, -0.869, -1.   , -1.   ,\n        -1.   , -1.   , -1.   , -0.921, -0.26 ,  0.386,  0.739,  1.   ,\n         0.477, -0.516, -0.991, -1.   , -1.   , -1.   , -1.   , -1.   ]))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test splitting functions\n",
    "data_train_123, data_test_123 = split_80_20(data_123, seed=637)\n",
    "X_train_123, y_train_123 = split_X_y(data_train_123)\n",
    "X_test_123, y_test_123 = split_X_y(data_test_123)\n",
    "\n",
    "assert X_train_123.shape[0] == y_train_123.size\n",
    "assert X_test_123.shape[0] == y_test_123.size\n",
    "\n",
    "print(\"Train data set size = %d\" % X_train_123.shape[0])\n",
    "print(\"Test data set size = %d\" % X_test_123.shape[0])\n",
    "\n",
    "# Testing data cleaning\n",
    "y_train_123[100], X_train_123[100]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def display_digit(grayscale):\n",
    "    plt.imshow(np.reshape(grayscale, (16, 16)), cmap='gray')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAdf0lEQVR4nO3dfWyV9R338c+hhUNl7dHW0XK0leKIKGBFEKKYCbGRNIiSTZ0Ga4OLzq0IpYZB3QpOhIpOV1FSxExhmfjwhyCyqEEEKps8Vpxkk4fYYZWVqtNzoEjB9rr/uG/PbaUPFK9fv+eU9ys5f5yHfq9vmpa3V3t5GvA8zxMAAN2sl/UCAIAzEwECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmkq0X+L6WlhYdPHhQqampCgQC1usAALrI8zwdPnxY4XBYvXq1f54TdwE6ePCgsrOzrdcAAPxAdXV1Ov/889t9Pu4ClJqaar3CGSc3N9fp/BkzZjibfcMNNzibnZGR4Wz29u3bnc1++OGHnc1+6623nM1Gz9PZv+dxFyB+7Nb9OjpF9kNKSoqz2S7/gyUtLc3Z7H79+jmb3bt3b2ezga7o7N9zLkIAAJggQAAAEwQIAGCCAAEATDgL0JIlSzRw4ED17dtXY8aM0bZt21wdCgCQgJwE6KWXXlJpaanmzZunmpoa5eXlacKECWpoaHBxOABAAnISoMcff1x33XWXpk6dqksuuURLly7VWWedpWeffdbF4QAACcj3AB0/flw7d+5Ufn7+/z9Ir17Kz8/Xu+++e9Lrm5qaFI1GW90AAD2f7wH6/PPP1dzcrMzMzFaPZ2Zmqr6+/qTXV1RUKBQKxW68DQ8AnBnMr4IrKytTJBKJ3erq6qxXAgB0A9/fiufcc89VUlKSDh061OrxQ4cOKSsr66TXB4NBBYNBv9cAAMQ538+A+vTpo5EjR2r9+vWxx1paWrR+/XpdeeWVfh8OAJCgnLwZaWlpqYqKijRq1CiNHj1alZWVamxs1NSpU10cDgCQgJwE6Be/+IU+++wzzZ07V/X19brsssv0xhtvnHRhAgDgzOXszzFMmzZN06ZNczUeAJDgzK+CAwCcmQgQAMAEAQIAmCBAAAATAc/zPOslvisajSoUClmvEXeuueYaZ7PXrFnjbLYkpaWlOZv9xRdfOJudnOzsGh2nX+PffPONs9kLFixwNvuBBx5wNhs2IpFIh9//nAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYCHie51kv8V3RaFShUMh6jdMybtw4Z7Nfe+01Z7O/+OILZ7MlaeHChc5m//Wvf3U2OxgMOps9YcIEZ7OrqqqczT7rrLOczXb5Odm4caOz2WhfJBJRWlpau89zBgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEz4HqCKigpdccUVSk1NVf/+/TV58mTt2bPH78MAABKc7wHatGmTiouLtWXLFq1bt04nTpzQddddp8bGRr8PBQBIYMl+D3zjjTda3V++fLn69++vnTt36qc//anfhwMAJCjfA/R9kUhEkpSent7m801NTWpqaordj0ajrlcCAMQBpxchtLS0qKSkRGPHjtWwYcPafE1FRYVCoVDslp2d7XIlAECccBqg4uJi7d69Wy+++GK7rykrK1MkEond6urqXK4EAIgTzn4EN23aNK1du1bV1dU6//zz231dMBh0+q7DAID45HuAPM/Tvffeq1WrVmnjxo3Kzc31+xAAgB7A9wAVFxdr5cqVevXVV5Wamqr6+npJUigUUkpKit+HAwAkKN9/B1RVVaVIJKJx48ZpwIABsdtLL73k96EAAAnMyY/gAADoDO8FBwAwQYAAACYIEADABAECAJhw/l5w8SYrK8vZ7L/97W/OZq9evdrZ7DvuuMPZbElqbm52Ot+Vo0ePOpvd0buD/FChUMjZ7KVLlzqb/ctf/tLZ7I0bNzqbjdPHGRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAICJgOd5nvUS3xWNRhUKhZzN/9GPfuRs9vz58xNy9v/+9z9ns9H9gsGgs9nHjh1zNru2ttbZ7EGDBjmbjfZFIhGlpaW1+zxnQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwITzAD388MMKBAIqKSlxfSgAQAJxGqDt27fr6aef1qWXXuryMACABOQsQEeOHNGUKVP0zDPP6JxzznF1GABAgnIWoOLiYk2cOFH5+fmuDgEASGDJLoa++OKLqqmp0fbt2zt9bVNTk5qammL3o9Goi5UAAHHG9zOguro6zZgxQ88//7z69u3b6esrKioUCoVit+zsbL9XAgDEId8DtHPnTjU0NOjyyy9XcnKykpOTtWnTJi1evFjJyclqbm5u9fqysjJFIpHYra6uzu+VAABxyPcfwV177bX64IMPWj02depUDRkyRLNnz1ZSUlKr54LBoNO3jwcAxCffA5Samqphw4a1eqxfv37KyMg46XEAwJmLd0IAAJhwchXc923cuLE7DgMASCCcAQEATBAgAIAJAgQAMEGAAAAmCBAAwES3XAUXT44cOeJs9syZM53NBk5V//79rVc4Ld9/lxT0fJwBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmEi2XgCAv0aPHm29wml5/fXXrVdAN+MMCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmHASoE8//VS33367MjIylJKSouHDh2vHjh0uDgUASFC+/4+oX375pcaOHavx48fr9ddf149//GPt27dP55xzjt+HAgAkMN8DtGjRImVnZ+u5556LPZabm+v3YQAACc73H8GtWbNGo0aN0s0336z+/ftrxIgReuaZZ9p9fVNTk6LRaKsbAKDn8z1AH330kaqqqjR48GC9+eab+vWvf63p06drxYoVbb6+oqJCoVAodsvOzvZ7JQBAHPI9QC0tLbr88su1cOFCjRgxQnfffbfuuusuLV26tM3Xl5WVKRKJxG51dXV+rwQAiEO+B2jAgAG65JJLWj128cUX6+OPP27z9cFgUGlpaa1uAICez/cAjR07Vnv27Gn12N69e3XBBRf4fSgAQALzPUAzZ87Uli1btHDhQu3fv18rV67UsmXLVFxc7PehAAAJzPcAXXHFFVq1apVeeOEFDRs2TPPnz1dlZaWmTJni96EAAAnMyV9Evf7663X99de7GA0A6CF4LzgAgAkCBAAwQYAAACYIEADAhJOLEADYmTx5svUKp6W6utp6BXQzzoAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMBDzP86yX+K5oNKpQKGS9BuDUyJEjnc1+5513nM3es2ePs9kjRoxwNhs2IpGI0tLS2n2eMyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGDC9wA1NzervLxcubm5SklJ0YUXXqj58+crzv53IwCAsWS/By5atEhVVVVasWKFhg4dqh07dmjq1KkKhUKaPn2634cDACQo3wP0j3/8QzfeeKMmTpwoSRo4cKBeeOEFbdu2ze9DAQASmO8/grvqqqu0fv167d27V5L0/vvva/PmzSooKGjz9U1NTYpGo61uAICez/czoDlz5igajWrIkCFKSkpSc3OzFixYoClTprT5+oqKCv3hD3/wew0AQJzz/Qzo5Zdf1vPPP6+VK1eqpqZGK1as0B//+EetWLGizdeXlZUpEonEbnV1dX6vBACIQ76fAc2aNUtz5szRrbfeKkkaPny4Dhw4oIqKChUVFZ30+mAwqGAw6PcaAIA45/sZ0NGjR9WrV+uxSUlJamlp8ftQAIAE5vsZ0KRJk7RgwQLl5ORo6NCheu+99/T444/rzjvv9PtQAIAE5nuAnnzySZWXl+s3v/mNGhoaFA6H9atf/Upz5871+1AAgATme4BSU1NVWVmpyspKv0cDAHoQ3gsOAGCCAAEATBAgAIAJAgQAMOH7RQhAT5GRkeFs9p///GdnswOBgLPZhYWFzmbjzMMZEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgIlk6wWAH+LSSy91NvuJJ55wNjsvL8/Z7MLCQmezd+/e7Ww2zjycAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABNdDlB1dbUmTZqkcDisQCCg1atXt3re8zzNnTtXAwYMUEpKivLz87Vv3z6/9gUA9BBdDlBjY6Py8vK0ZMmSNp9/5JFHtHjxYi1dulRbt25Vv379NGHCBB07duwHLwsA6Dm6/E4IBQUFKigoaPM5z/NUWVmp3//+97rxxhslSX/5y1+UmZmp1atX69Zbb/1h2wIAegxffwdUW1ur+vp65efnxx4LhUIaM2aM3n333TY/pqmpSdFotNUNANDz+Rqg+vp6SVJmZmarxzMzM2PPfV9FRYVCoVDslp2d7edKAIA4ZX4VXFlZmSKRSOxWV1dnvRIAoBv4GqCsrCxJ0qFDh1o9fujQodhz3xcMBpWWltbqBgDo+XwNUG5urrKysrR+/frYY9FoVFu3btWVV17p56EAAAmuy1fBHTlyRPv374/dr62t1a5du5Senq6cnByVlJTooYce0uDBg5Wbm6vy8nKFw2FNnjzZz70BAAmuywHasWOHxo8fH7tfWloqSSoqKtLy5cv129/+Vo2Njbr77rv11Vdf6eqrr9Ybb7yhvn37+rc1ACDhdTlA48aNk+d57T4fCAT04IMP6sEHH/xBiwEAejbzq+AAAGcmAgQAMEGAAAAmCBAAwESXL0JAz/OTn/zE6fxHH33U2exv3/TWhcbGRmezXe792muvOZsN+IkzIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABPJ1gvg1Dz22GPOZk+bNs3ZbEnq06ePs9mbN292Nvuuu+5yNvvDDz90NhsnS0tLczp/5MiRzmZv2bLF2eyvv/7a2exTwRkQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAw0eUAVVdXa9KkSQqHwwoEAlq9enXsuRMnTmj27NkaPny4+vXrp3A4rDvuuEMHDx70c2cAQA/Q5QA1NjYqLy9PS5YsOem5o0ePqqamRuXl5aqpqdErr7yiPXv26IYbbvBlWQBAz9Hld0IoKChQQUFBm8+FQiGtW7eu1WNPPfWURo8erY8//lg5OTmntyUAoMdx/lY8kUhEgUBAZ599dpvPNzU1qampKXY/Go26XgkAEAecXoRw7NgxzZ49W7fddlu778VUUVGhUCgUu2VnZ7tcCQAQJ5wF6MSJE7rlllvkeZ6qqqrafV1ZWZkikUjsVldX52olAEAccfIjuG/jc+DAAb399tsdvhNtMBhUMBh0sQYAII75HqBv47Nv3z5t2LBBGRkZfh8CANADdDlAR44c0f79+2P3a2trtWvXLqWnp2vAgAG66aabVFNTo7Vr16q5uVn19fWSpPT0dKd/FwYAkFi6HKAdO3Zo/PjxsfulpaWSpKKiIj3wwANas2aNJOmyyy5r9XEbNmzQuHHjTn9TAECP0uUAjRs3Tp7ntft8R88BAPAt3gsOAGCCAAEATBAgAIAJAgQAMEGAAAAmnL8Z6Znku5en++3by90T0f333+9s9rPPPuts9vHjx53NHjp0qLPZgwYNcjZ72LBhzmZfc801zmbn5+c7my1J//3vf53NzsvLczb766+/djb7VHAGBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYCLgeZ5nvcR3RaNRhUIh6zVOy3nnnedsdnV1tbPZgwYNcjbbtSNHjjib3dzc7Gx2on6Nf/bZZ85mu/wa3717t7PZklRZWels9ldffeVstmuRSERpaWntPs8ZEADABAECAJggQAAAEwQIAGCCAAEATBAgAICJLgeourpakyZNUjgcViAQ0OrVq9t97T333KNAIOD0EkUAQGLqcoAaGxuVl5enJUuWdPi6VatWacuWLQqHw6e9HACg50ru6gcUFBSooKCgw9d8+umnuvfee/Xmm29q4sSJp70cAKDn8v13QC0tLSosLNSsWbM0dOhQv8cDAHqILp8BdWbRokVKTk7W9OnTT+n1TU1Nampqit2PRqN+rwQAiEO+ngHt3LlTTzzxhJYvX65AIHBKH1NRUaFQKBS7ZWdn+7kSACBO+Rqgd955Rw0NDcrJyVFycrKSk5N14MAB3XfffRo4cGCbH1NWVqZIJBK71dXV+bkSACBO+fojuMLCQuXn57d6bMKECSosLNTUqVPb/JhgMKhgMOjnGgCABNDlAB05ckT79++P3a+trdWuXbuUnp6unJwcZWRktHp97969lZWVpYsuuuiHbwsA6DG6HKAdO3Zo/PjxsfulpaWSpKKiIi1fvty3xQAAPVuXAzRu3Dh15W/Y/ec//+nqIQAAZwDeCw4AYIIAAQBMECAAgAkCBAAwQYAAACYCXlcuaesG0WhUoVDIeo24c9ZZZzmbfdNNNzmbLUk///nPnc0ePny4s9m5ubnOZr/99tvOZs+bN8/Z7L///e/OZsfZP0XwQSQSUVpaWrvPcwYEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABPJ1gt8n+d51ivEJZefl+PHjzubLUlHjx51Nvvw4cPOZkejUWezGxsbnc3+5ptvnM3m+xNd0dnXS8CLs6+oTz75RNnZ2dZrAAB+oLq6Op1//vntPh93AWppadHBgweVmpqqQCDQ6euj0aiys7NVV1entLS0btjQH+zdvRJ1bylxd2fv7hVPe3uep8OHDyscDqtXr/Z/0xN3P4Lr1atXh8VsT1pamvkn/XSwd/dK1L2lxN2dvbtXvOwdCoU6fQ0XIQAATBAgAICJhA9QMBjUvHnzFAwGrVfpEvbuXom6t5S4u7N390rEvePuIgQAwJkh4c+AAACJiQABAEwQIACACQIEADCR0AFasmSJBg4cqL59+2rMmDHatm2b9Uqdqqio0BVXXKHU1FT1799fkydP1p49e6zX6rKHH35YgUBAJSUl1qt06tNPP9Xtt9+ujIwMpaSkaPjw4dqxY4f1Wh1qbm5WeXm5cnNzlZKSogsvvFDz58+Py/diq66u1qRJkxQOhxUIBLR69epWz3uep7lz52rAgAFKSUlRfn6+9u3bZ7Psd3S094kTJzR79mwNHz5c/fr1Uzgc1h133KGDBw/aLfz/dPb5/q577rlHgUBAlZWV3bZfVyRsgF566SWVlpZq3rx5qqmpUV5eniZMmKCGhgbr1Tq0adMmFRcXa8uWLVq3bp1OnDih6667zumbU/pt+/btevrpp3XppZdar9KpL7/8UmPHjlXv3r31+uuv61//+pcee+wxnXPOOdardWjRokWqqqrSU089pX//+99atGiRHnnkET355JPWq52ksbFReXl5WrJkSZvPP/LII1q8eLGWLl2qrVu3ql+/fpowYYKOHTvWzZu21tHeR48eVU1NjcrLy1VTU6NXXnlFe/bs0Q033GCwaWudfb6/tWrVKm3ZskXhcLibNjsNXoIaPXq0V1xcHLvf3NzshcNhr6KiwnCrrmtoaPAkeZs2bbJe5ZQcPnzYGzx4sLdu3Trvmmuu8WbMmGG9Uodmz57tXX311dZrdNnEiRO9O++8s9VjP/vZz7wpU6YYbXRqJHmrVq2K3W9pafGysrK8Rx99NPbYV1995QWDQe+FF14w2LBt39+7Ldu2bfMkeQcOHOiepU5Be3t/8skn3nnnneft3r3bu+CCC7w//elP3b7bqUjIM6Djx49r586dys/Pjz3Wq1cv5efn69133zXcrOsikYgkKT093XiTU1NcXKyJEye2+tzHszVr1mjUqFG6+eab1b9/f40YMULPPPOM9Vqduuqqq7R+/Xrt3btXkvT+++9r8+bNKigoMN6sa2pra1VfX9/q6yUUCmnMmDEJ+b0aCAR09tlnW6/SoZaWFhUWFmrWrFkaOnSo9Todirs3Iz0Vn3/+uZqbm5WZmdnq8czMTH344YdGW3VdS0uLSkpKNHbsWA0bNsx6nU69+OKLqqmp0fbt261XOWUfffSRqqqqVFpaqvvvv1/bt2/X9OnT1adPHxUVFVmv1645c+YoGo1qyJAhSkpKUnNzsxYsWKApU6ZYr9Yl9fX1ktTm9+q3zyWCY8eOafbs2brtttvi4o0+O7Jo0SIlJydr+vTp1qt0KiED1FMUFxdr9+7d2rx5s/Uqnaqrq9OMGTO0bt069e3b13qdU9bS0qJRo0Zp4cKFkqQRI0Zo9+7dWrp0aVwH6OWXX9bzzz+vlStXaujQodq1a5dKSkoUDofjeu+e6MSJE7rlllvkeZ6qqqqs1+nQzp079cQTT6impuaU/pyNtYT8Edy5556rpKQkHTp0qNXjhw4dUlZWltFWXTNt2jStXbtWGzZsOK0/P9Hddu7cqYaGBl1++eVKTk5WcnKyNm3apMWLFys5OVnNzc3WK7ZpwIABuuSSS1o9dvHFF+vjjz822ujUzJo1S3PmzNGtt96q4cOHq7CwUDNnzlRFRYX1al3y7fdjon6vfhufAwcOaN26dXF/9vPOO++ooaFBOTk5se/TAwcO6L777tPAgQOt1ztJQgaoT58+GjlypNavXx97rKWlRevXr9eVV15puFnnPM/TtGnTtGrVKr399tvKzc21XumUXHvttfrggw+0a9eu2G3UqFGaMmWKdu3apaSkJOsV2zR27NiTLnPfu3evLrjgAqONTs3Ro0dP+kNeSUlJamlpMdro9OTm5iorK6vV92o0GtXWrVvj/nv12/js27dPb731ljIyMqxX6lRhYaH++c9/tvo+DYfDmjVrlt58803r9U6SsD+CKy0tVVFRkUaNGqXRo0ersrJSjY2Nmjp1qvVqHSouLtbKlSv16quvKjU1NfZz8FAopJSUFOPt2peamnrS76n69eunjIyMuP791cyZM3XVVVdp4cKFuuWWW7Rt2zYtW7ZMy5Yts16tQ5MmTdKCBQuUk5OjoUOH6r333tPjjz+uO++803q1kxw5ckT79++P3a+trdWuXbuUnp6unJwclZSU6KGHHtLgwYOVm5ur8vJyhcNhTZ482W5pdbz3gAEDdNNNN6mmpkZr165Vc3Nz7Hs1PT1dffr0sVq708/390PZu3dvZWVl6aKLLuruVTtnfRneD/Hkk096OTk5Xp8+fbzRo0d7W7ZssV6pU5LavD333HPWq3VZIlyG7Xme99prr3nDhg3zgsGgN2TIEG/ZsmXWK3UqGo16M2bM8HJycry+fft6gwYN8n73u995TU1N1qudZMOGDW1+TRcVFXme938vxS4vL/cyMzO9YDDoXXvttd6ePXtsl/Y63ru2trbd79UNGzbE7d5tiefLsPlzDAAAEwn5OyAAQOIjQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEz8H6Epd1FcBE24AAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_digit(X_train_123[100])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us now define the Kernel Perceptron algorithm and kernel functions to be used."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def polynomial_kernel(x_i: np.ndarray, x_t: np.ndarray, d: int):\n",
    "    return np.inner(x_i, x_t) ** d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def gaussian_kernel(x_i: np.ndarray, x_j: np.ndarray, sigma=1):\n",
    "    if x_i.shape[0] != x_j.shape[0]:\n",
    "        raise Exception(\"Cannot apply kernel to vectors of different dimensions: x_i has shape {s1}, x_j has shape {s2}\"\n",
    "                        .format(s1=x_i.shape, s2=x_j.shape))\n",
    "    diff = x_i - x_j\n",
    "    return np.exp(-1 * np.inner(diff, diff) / (2 * sigma**2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def get_num_mistakes(actual: np.ndarray, predicted: np.ndarray) -> int:\n",
    "    # or calculating by checking which alpha values are different than 0? alpha is 0 when the prediction matches\n",
    "    diffs = actual - predicted\n",
    "    n_mistakes = 0\n",
    "    for diff in diffs:\n",
    "        if diff != 0:\n",
    "            n_mistakes += 1\n",
    "    return n_mistakes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def get_error_percentage(y_train, y_insample, y_test, y_outsample):\n",
    "    print(\"in-sample = % \" + str(100 * get_num_mistakes(actual=y_train, predicted=y_insample) / y_train.size))\n",
    "    print(\"out-of-sample = % \" + str(100 * get_num_mistakes(actual=y_test, predicted=y_outsample) / y_test.size))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class KernelPerceptron:\n",
    "    def __init__(self, kernel: Callable[[np.ndarray, np.ndarray], float], size: int):\n",
    "        self.kernel = kernel\n",
    "        self.K = None\n",
    "        self.alpha = np.zeros(size)\n",
    "        self.X_train = None\n",
    "\n",
    "    def _get_kernel_matrix(self, X_train: np.ndarray) -> np.ndarray:\n",
    "        K = np.zeros((X_train.shape[0], X_train.shape[0]))\n",
    "\n",
    "        for i in range(0, X_train.shape[0]):\n",
    "            for j in range(i, X_train.shape[0]):\n",
    "                K[i, j] = K[j, i] = self.kernel(X_train[i], X_train[j])\n",
    "\n",
    "        return K\n",
    "\n",
    "    def fit(self, X_train: np.ndarray, y_train: np.ndarray, n_epochs: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Prediction function that populates the alpha parameter, 1 data point at a time;\n",
    "        :param X_train: training data points\n",
    "        :param y_train: training corresponding labels\n",
    "        :param n_epochs: number of times to pass through the data. Alpha contains the learning parameters that get inherited from one epoch to the other\n",
    "        :return: y_preds: the predictions enhanced after N epochs\n",
    "\n",
    "        \"\"\"\n",
    "        if y_train.ndim != 1:\n",
    "            raise Exception('y_train must be a 1-dim np.ndarray. Given y_train with shape {s}'.format(s=y_train.shape))\n",
    "        if X_train.shape[0] != y_train.size:\n",
    "            raise Exception('X_train and y_train must contain equal number of samples. Given X_train with shape {s1} and y_train with shape {s2}'.format(s1=y_train.shape, s2=X_train.shape))\n",
    "\n",
    "        y_preds = np.zeros(X_train.shape[0])\n",
    "        self.X_train = X_train\n",
    "\n",
    "        # Compute kernel matrix which stays constant throughout the algorithm and all epochs\n",
    "        self.K = self._get_kernel_matrix(X_train)\n",
    "\n",
    "        for epoch in range(0, n_epochs):\n",
    "            for t in range(0, X_train.shape[0]):\n",
    "                y_pred = self._predict_single(t)\n",
    "                y_preds[t] = y_pred\n",
    "                if y_pred != y_train[t]:\n",
    "                    self.alpha[t] += y_train[t]\n",
    "        return y_preds\n",
    "\n",
    "    def _predict_single(self, t: int):\n",
    "        \"\"\"\n",
    "        We take a whole row of kernel matrix K because in we want to account for errors in previous epochs.\n",
    "        This is not an issue in the first epoch because all alpha's > t are 0.\n",
    "        :param t: iteration step in the online learning algorithm.\n",
    "        :return: y hat, single predicted value at step t.\n",
    "        \"\"\"\n",
    "        return np.sign(np.inner(self.K[t, :], self.alpha))\n",
    "\n",
    "    def yhat_single(self, y_train, K, t: int):\n",
    "        return np.sign(np.inner(K[t, :], self.alpha))\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Prediction function to be used for out-of-sample test data point.\n",
    "        Does not perform online learning (update step).\n",
    "        :param X: test data points.\n",
    "        :return: np.ndarray of predictions for each given test data point.\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        for x_test in X:\n",
    "            sum = 0\n",
    "            for t in range(self.X_train.shape[0]):\n",
    "                # Can improve by using kernel matrix\n",
    "                sum += self.alpha[t] * self.kernel(self.X_train[t], x_test)\n",
    "            predictions.append(np.sign(sum))\n",
    "        return np.array(predictions)\n",
    "\n",
    "\n",
    "# kp = KernelPerceptron(kernel=partial(polynomial_kernel, d=3))\n",
    "# y_insample = kp.fit(X_train_12, y_train_12, n_epochs=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[29], line 87\u001B[0m\n\u001B[0;32m     85\u001B[0m kpova \u001B[38;5;241m=\u001B[39m KPOneVsAllClassifier(polynomial_kernel, n_classes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, d\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m7\u001B[39m)\n\u001B[0;32m     86\u001B[0m y_insample \u001B[38;5;241m=\u001B[39m kpova\u001B[38;5;241m.\u001B[39mfit(X_train_123, y_train_123, n_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m15\u001B[39m)\n\u001B[1;32m---> 87\u001B[0m y_outsample \u001B[38;5;241m=\u001B[39m \u001B[43mkpova\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test_123\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     89\u001B[0m get_error_percentage(y_train_123, y_insample, y_test_123, y_outsample)\n",
      "Cell \u001B[1;32mIn[29], line 76\u001B[0m, in \u001B[0;36mKPOneVsAllClassifier.predict\u001B[1;34m(self, X_test)\u001B[0m\n\u001B[0;32m     72\u001B[0m \u001B[38;5;66;03m# cl can start from 0 here since we do not compare it anywhere\u001B[39;00m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m cl \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes):\n\u001B[0;32m     74\u001B[0m     \u001B[38;5;66;03m# update\u001B[39;00m\n\u001B[0;32m     75\u001B[0m     \u001B[38;5;66;03m# BUG: sum never under 0 since alpha>0 always and k(X_train, X_test)>0=>sign(sum)=1\u001B[39;00m\n\u001B[1;32m---> 76\u001B[0m     \u001B[38;5;28msum\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     77\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mX_train\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]):\n\u001B[0;32m     78\u001B[0m         \u001B[38;5;28msum\u001B[39m \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mperceptrons[cl]\u001B[38;5;241m.\u001B[39malpha[t] \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkernel(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mX_train[t], X_test[t_test], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39md)\n",
      "Cell \u001B[1;32mIn[29], line 76\u001B[0m, in \u001B[0;36mKPOneVsAllClassifier.predict\u001B[1;34m(self, X_test)\u001B[0m\n\u001B[0;32m     72\u001B[0m \u001B[38;5;66;03m# cl can start from 0 here since we do not compare it anywhere\u001B[39;00m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m cl \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes):\n\u001B[0;32m     74\u001B[0m     \u001B[38;5;66;03m# update\u001B[39;00m\n\u001B[0;32m     75\u001B[0m     \u001B[38;5;66;03m# BUG: sum never under 0 since alpha>0 always and k(X_train, X_test)>0=>sign(sum)=1\u001B[39;00m\n\u001B[1;32m---> 76\u001B[0m     \u001B[38;5;28msum\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     77\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mX_train\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]):\n\u001B[0;32m     78\u001B[0m         \u001B[38;5;28msum\u001B[39m \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mperceptrons[cl]\u001B[38;5;241m.\u001B[39malpha[t] \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkernel(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mX_train[t], X_test[t_test], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39md)\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:1095\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:1053\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\AppData\\Local\\JetBrains\\Toolbox\\apps\\PyCharm-P\\ch-0\\222.3739.56\\plugins\\python\\helpers-pro\\jupyter_debug\\pydev_jupyter_plugin.py:169\u001B[0m, in \u001B[0;36mstop\u001B[1;34m(plugin, pydb, frame, event, args, stop_info, arg, step_cmd)\u001B[0m\n\u001B[0;32m    167\u001B[0m     frame \u001B[38;5;241m=\u001B[39m suspend_jupyter(main_debugger, thread, frame, step_cmd)\n\u001B[0;32m    168\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m frame:\n\u001B[1;32m--> 169\u001B[0m         \u001B[43mmain_debugger\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    170\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    171\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\JetBrains\\Toolbox\\apps\\PyCharm-P\\ch-0\\222.3739.56\\plugins\\python\\helpers\\pydev\\pydevd.py:1160\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1157\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1159\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1160\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\JetBrains\\Toolbox\\apps\\PyCharm-P\\ch-0\\222.3739.56\\plugins\\python\\helpers\\pydev\\pydevd.py:1175\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1174\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1175\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1179\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "class KPOneVsAllClassifier():\n",
    "    def __init__(self, kernel, n_classes, d):\n",
    "        self.kernel = kernel\n",
    "        self.n_classes = n_classes # could optimize to remove this var since =k.shape[0]\n",
    "        self.d = d\n",
    "\n",
    "    def _get_kernel_matrix(self, X_train: np.ndarray) -> np.ndarray:\n",
    "        K = np.zeros((X_train.shape[0], X_train.shape[0]))\n",
    "        for i in range(0, X_train.shape[0]):\n",
    "            for j in range(i, X_train.shape[0]):\n",
    "                K[i, j] = K[j, i] = self.kernel(X_train[i], X_train[j], d=self.d)\n",
    "        return K\n",
    "\n",
    "    def _create_perceptrons(self):\n",
    "        perceptrons = []\n",
    "        for cl in range(self.n_classes):\n",
    "            perceptrons.append(KernelPerceptron(kernel=partial(polynomial_kernel, d=self.d), size=self.X_train.shape[0]))\n",
    "        return np.array(perceptrons)\n",
    "\n",
    "    def _predict_single_confidence(self, t, perceptrons, y_train):\n",
    "        confidence = np.array(np.zeros(self.n_classes))\n",
    "        for cl in range(1, self.n_classes+1):\n",
    "            ### cl-1 because perceptrons' list begins from 0\n",
    "            yhat = perceptrons[cl-1].yhat_single(y_train, self.K, t)\n",
    "            if y_train[t] == float(cl):\n",
    "                if yhat <= 0:\n",
    "                    ## penilize if the prediction is negative for the respective class\n",
    "                    perceptrons[cl-1].alpha[t]+=y_train[t]\n",
    "                else:\n",
    "                    ## if prediction is pozitive for the respective perceptron class, do not penilize and add confidence\n",
    "                    confidence[cl-1]+=y_train[t]\n",
    "            else:\n",
    "                ## if prediction is pozitive for other perceptrons, penalize them\n",
    "                if yhat >= 0:\n",
    "                    perceptrons[cl-1].alpha[t]+=y_train[t]\n",
    "        return confidence\n",
    "\n",
    "    def fit(self, X_train, y_train, n_epochs):\n",
    "        y_preds = np.array(np.zeros(X_train.shape[0]))\n",
    "\n",
    "        self.K = self._get_kernel_matrix(X_train)\n",
    "        self.X_train = X_train\n",
    "\n",
    "        # create all perceptrons\n",
    "        self.perceptrons = self._create_perceptrons()\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            # for each point, calculate confidence and make predictions\n",
    "            for t in range(0, X_train.shape[0]):\n",
    "                confidence = self._predict_single_confidence(t, self.perceptrons, y_train)\n",
    "                # the index with the highest number(confidence) is the prediction\n",
    "                # +1 because the index for confidence in perceptron for number 1 is 0\n",
    "                y_preds[t] = np.argmax(confidence)+1\n",
    "        # here\n",
    "        return y_preds\n",
    "\n",
    "    def _choose_best_ytest(self, yhats):\n",
    "        # get the classifiers that predicted positive\n",
    "        maxims = np.argwhere(yhats == np.amax(yhats)).flatten()\n",
    "        if maxims.shape[0] == 1:\n",
    "            # if only 1 classifier predicts positive, take that class\n",
    "             return maxims[0]\n",
    "        else:\n",
    "            # if more than one predicted positive, or all of them negative, choose one randomly\n",
    "            return np.random.choice(maxims)\n",
    "\n",
    "    def predict(self, X_test: np.ndarray):\n",
    "        ypreds = np.array(np.zeros(X_test.shape[0]))\n",
    "\n",
    "        for t_test in range(X_test.shape[0]):\n",
    "            yhats = np.array(np.zeros(self.n_classes))\n",
    "            # cl can start from 0 here since we do not compare it anywhere\n",
    "            for cl in range(self.n_classes):\n",
    "                # update\n",
    "                # BUG: sum never under 0 since alpha>0 always and k(X_train, X_test)>0=>sign(sum)=1\n",
    "                sum = 0\n",
    "                for t in range(self.X_train.shape[0]):\n",
    "                    sum += self.perceptrons[cl].alpha[t] * self.kernel(self.X_train[t], X_test[t_test], self.d)\n",
    "                yhats[cl] = np.sign(sum)\n",
    "            ypreds[t_test] = self._choose_best_ytest(yhats)\n",
    "\n",
    "        return ypreds\n",
    "\n",
    "\n",
    "kpova = KPOneVsAllClassifier(polynomial_kernel, n_classes=3, d=7)\n",
    "y_insample = kpova.fit(X_train_123, y_train_123, n_epochs=15)\n",
    "y_outsample = kpova.predict(X_test_123)\n",
    "\n",
    "get_error_percentage(y_train_123, y_insample, y_test_123, y_outsample)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample = % 0.38022813688212925\n",
      "out-of-sample = % 78.78787878787878\n"
     ]
    }
   ],
   "source": [
    "kpova = KPOneVsAllClassifier(polynomial_kernel, 3, 3)\n",
    "y_insample = kpova.fit(X_train_123, y_train_123, n_epochs=1)\n",
    "y_outsample = kpova.predict(X_test_123)\n",
    "\n",
    "get_error_percentage(y_train_123, y_insample, y_test_123, y_outsample)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us test the Kernel Perceptron implementation on a dummy dataset of only digits 1 and 2."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Filter out digit 3 (leave only digit 1 and 2) from dtrain123.dat train and test dataset\n",
    "indxs_digit_3 = np.where(y_train_123 == 3)\n",
    "X_train_12 = np.delete(X_train_123, indxs_digit_3, axis=0)\n",
    "y_train_12 = np.delete(y_train_123, indxs_digit_3)\n",
    "y_train_12[y_train_12 == 1] = -1\n",
    "y_train_12[y_train_12 == 2] = 1\n",
    "\n",
    "indxs_digit_3 = np.where(y_test_123 == 3)\n",
    "X_test_12 = np.delete(X_test_123, indxs_digit_3, axis=0)\n",
    "y_test_12 = np.delete(y_test_123, indxs_digit_3)\n",
    "y_test_12[y_test_12 == 1] = -1\n",
    "y_test_12[y_test_12 == 2] = 1\n",
    "\n",
    "assert X_train_12.shape[0] == y_train_12.size\n",
    "assert X_test_12.shape[0] == y_test_12.size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample = % 0.0\n",
      "out-of-sample = % 1.8518518518518519\n"
     ]
    }
   ],
   "source": [
    "# Test fitting and in-sample predictions\n",
    "kp = KernelPerceptron(kernel=partial(polynomial_kernel, d=5), size=X_train_12.shape[0])\n",
    "y_insample = kp.fit(X_train_12, y_train_12, n_epochs=2)\n",
    "# Test out-of-sample predictions\n",
    "y_outsample = kp.predict(X_test_12) # all predictions of test sample in y_outsample\n",
    "print(\"in-sample = % \" + str(100 * get_num_mistakes(actual=y_train_12, predicted=y_insample) / y_train_12.size))\n",
    "print(\"out-of-sample = % \" + str(100 * get_num_mistakes(actual=y_test_12, predicted=y_outsample) / y_test_12.size))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "KernelPerceptron.__init__() missing 1 required positional argument: 'size'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[69], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m## Test the kernel matrix\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m kp_test \u001B[38;5;241m=\u001B[39m \u001B[43mKernelPerceptron\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkernel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpartial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpolynomial_kernel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43md\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m kernel_matrix \u001B[38;5;241m=\u001B[39m kp_test\u001B[38;5;241m.\u001B[39m_get_kernel_matrix(X_train_12)\n\u001B[0;32m      4\u001B[0m polynomial_kernel(X_train_12[\u001B[38;5;241m0\u001B[39m], X_train_12[\u001B[38;5;241m0\u001B[39m], d\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m) \u001B[38;5;241m==\u001B[39m kernel_matrix[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[1;31mTypeError\u001B[0m: KernelPerceptron.__init__() missing 1 required positional argument: 'size'"
     ]
    }
   ],
   "source": [
    "## Test the kernel matrix\n",
    "kp_test = KernelPerceptron(kernel=partial(polynomial_kernel, d=3))\n",
    "kernel_matrix = kp_test._get_kernel_matrix(X_train_12)\n",
    "polynomial_kernel(X_train_12[0], X_train_12[0], d=3) == kernel_matrix[0][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}