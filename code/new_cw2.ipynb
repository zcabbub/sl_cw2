{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Importing all modules in cell below."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from typing import Callable, Iterable"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load dummy 1-2-3 digit dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data = np.loadtxt('../support/zipcombo.dat')\n",
    "# data_123 = np.loadtxt('../support/dtrain123.dat')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(9298, 257)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now define functions for splitting the dataset into train/test and input/label."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def split_80_20(data: np.ndarray, seed: int) -> (np.ndarray, np.ndarray):\n",
    "    \"\"\"\n",
    "    Splits 80% train 20% test\n",
    "\n",
    "    :param data: sequence.\n",
    "    :param seed: Random seed used to shuffle given data.\n",
    "    :return: train_data, test_data: np.ndarray, np.ndarray\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    n = data.shape[0]\n",
    "    shuffle = np.random.permutation(data)\n",
    "    train_size = int(n*0.8)\n",
    "    return shuffle[:train_size], shuffle[train_size:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def split_X_y(data: np.ndarray) -> (np.ndarray, np.ndarray):\n",
    "    \"\"\"\n",
    "    Splits the data into datapoints and labels, X_train matrix and y_train;\n",
    "    :param data: np.ndarray\n",
    "    :return: X_train, y_train: np.ndarray, np.ndarray\n",
    "    \"\"\"\n",
    "\n",
    "    return data[:, 1:], data[:, 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def shuffle_split(data):\n",
    "    data_train, data_test = split_80_20(data, seed=637)\n",
    "    X_train, y_train = split_X_y(data_train)\n",
    "    X_test, y_test = split_X_y(data_test)\n",
    "\n",
    "    assert X_train.shape[0] == y_train.size\n",
    "    assert X_test.shape[0] == y_test.size\n",
    "\n",
    "    print(\"Train data set size = %d\" % X_train.shape[0])\n",
    "    print(\"Test data set size = %d\" % X_test.shape[0])\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data set size = 7438\n",
      "Test data set size = 1860\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = shuffle_split(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def display_digit(grayscale):\n",
    "    plt.imshow(np.reshape(grayscale, (16, 16)), cmap='gray')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_digit(X_train[100])\n",
    "print(y_train[100])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us now define the Kernel Perceptron algorithm and kernel functions to be used."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def polynomial_kernel(x_i: np.ndarray, x_t: np.ndarray, d: int):\n",
    "    return np.inner(x_i, x_t) ** d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def gaussian_kernel(x_i: np.ndarray, x_j: np.ndarray, sigma=1):\n",
    "    if x_i.shape[0] != x_j.shape[0]:\n",
    "        raise Exception(\"Cannot apply kernel to vectors of different dimensions: x_i has shape {s1}, x_j has shape {s2}\"\n",
    "                        .format(s1=x_i.shape, s2=x_j.shape))\n",
    "    diff = x_i - x_j\n",
    "    return np.exp(-1 * np.inner(diff, diff) / (2 * sigma**2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class KernelPerceptron:\n",
    "    def __init__(self, kernel: Callable[[np.ndarray, np.ndarray], float], size: int):\n",
    "        self.kernel = kernel\n",
    "        self.K = None\n",
    "        self.alpha = np.zeros(size)\n",
    "        self.X_train = None\n",
    "\n",
    "    def _get_kernel_matrix(self, X_train: np.ndarray) -> np.ndarray:\n",
    "        K = np.zeros((X_train.shape[0], X_train.shape[0]))\n",
    "\n",
    "        for i in range(0, X_train.shape[0]):\n",
    "            for j in range(i, X_train.shape[0]):\n",
    "                K[i, j] = K[j, i] = self.kernel(X_train[i], X_train[j])\n",
    "\n",
    "        return K\n",
    "\n",
    "    def fit(self, X_train: np.ndarray, y_train: np.ndarray, n_epochs: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Prediction function that populates the alpha parameter, 1 data point at a time;\n",
    "        :param X_train: training data points\n",
    "        :param y_train: training corresponding labels\n",
    "        :param n_epochs: number of times to pass through the data. Alpha contains the learning parameters that get inherited from one epoch to the other\n",
    "        :return: y_preds: the predictions enhanced after N epochs\n",
    "\n",
    "        \"\"\"\n",
    "        if y_train.ndim != 1:\n",
    "            raise Exception('y_train must be a 1-dim np.ndarray. Given y_train with shape {s}'.format(s=y_train.shape))\n",
    "        if X_train.shape[0] != y_train.size:\n",
    "            raise Exception('X_train and y_train must contain equal number of samples. Given X_train with shape {s1} and y_train with shape {s2}'.format(s1=y_train.shape, s2=X_train.shape))\n",
    "\n",
    "        y_preds = np.zeros(X_train.shape[0])\n",
    "        self.X_train = X_train\n",
    "\n",
    "        # Compute kernel matrix which stays constant throughout the algorithm and all epochs\n",
    "        self.K = self._get_kernel_matrix(X_train)\n",
    "\n",
    "        for epoch in range(0, n_epochs):\n",
    "            for t in range(0, X_train.shape[0]):\n",
    "                y_pred = self._predict_single(t)\n",
    "                y_preds[t] = y_pred\n",
    "                if y_pred != y_train[t]:\n",
    "                    self.alpha[t] += y_train[t]\n",
    "        return y_preds\n",
    "\n",
    "    def _predict_single(self, t: int):\n",
    "        \"\"\"\n",
    "        We take a whole row of kernel matrix K because in we want to account for errors in previous epochs.\n",
    "        This is not an issue in the first epoch because all alpha's > t are 0.\n",
    "        :param t: iteration step in the online learning algorithm.\n",
    "        :return: y hat, single predicted value at step t.\n",
    "        \"\"\"\n",
    "        return np.sign(np.inner(self.K[t, :], self.alpha))\n",
    "\n",
    "    def yhat_single(self, K, t: int):\n",
    "        return np.sign(np.inner(K[t, :], self.alpha))\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Prediction function to be used for out-of-sample test data point.\n",
    "        Does not perform online learning (update step).\n",
    "        :param X: test data points.\n",
    "        :return: np.ndarray of predictions for each given test data point.\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        for x_test in X:\n",
    "            sum = 0\n",
    "            for t in range(self.X_train.shape[0]):\n",
    "                # Can improve by using kernel matrix\n",
    "                sum += self.alpha[t] * self.kernel(self.X_train[t], x_test)\n",
    "            predictions.append(np.sign(sum))\n",
    "        return np.array(predictions)\n",
    "\n",
    "\n",
    "# kp = KernelPerceptron(kernel=partial(polynomial_kernel, d=3))\n",
    "# y_insample = kp.fit(X_train_12, y_train_12, n_epochs=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def get_error_percentage(y_train, y_insample, y_test, y_outsample):\n",
    "    print(\"in-sample = % \" + str(100 * get_num_mistakes(actual=y_train, predicted=y_insample) / y_train.size))\n",
    "    print(\"out-of-sample = % \" + str(100 * get_num_mistakes(actual=y_test, predicted=y_outsample) / y_test.size))\n",
    "\n",
    "def get_num_mistakes(actual: np.ndarray, predicted: np.ndarray) -> int:\n",
    "    # or calculating by checking which alpha values are different than 0? alpha is 0 when the prediction matches\n",
    "    diffs = actual - predicted\n",
    "    n_mistakes = 0\n",
    "    for diff in diffs:\n",
    "        if diff != 0:\n",
    "            n_mistakes += 1\n",
    "    return n_mistakes\n",
    "\n",
    "class KPOneVsAllClassifier():\n",
    "    def __init__(self, kernel, n_classes, d):\n",
    "        self.kernel = kernel\n",
    "        self.n_classes = n_classes # could optimize to remove this var since =k.shape[0]\n",
    "        self.d = d\n",
    "        self.X_train = None\n",
    "        self.Alpha = None\n",
    "        self.K = None\n",
    "\n",
    "    def _get_kernel_matrix(self, X_train: np.ndarray) -> np.ndarray:\n",
    "        K = np.zeros((X_train.shape[0], X_train.shape[0]))\n",
    "        for i in range(0, X_train.shape[0]):\n",
    "            for j in range(i, X_train.shape[0]):\n",
    "                K[i, j] = K[j, i] = self.kernel(X_train[i], X_train[j], d=self.d)\n",
    "        return K\n",
    "\n",
    "    def sign(self, x: np.ndarray) -> np.ndarray:\n",
    "        return np.where(x <= 0, 1, -1)\n",
    "\n",
    "    def _predict_single_confidence(self, t, y_train):\n",
    "        confidence = np.array(np.zeros(self.n_classes))\n",
    "\n",
    "        # Get prediction array P\n",
    "        preds = np.inner(self.K[t, :], self.Alpha[:, t])\n",
    "\n",
    "        # Get Y_t array of ground truth (duplicate y_t)\n",
    "        y = np.full(self.n_classes, -1)\n",
    "        y[y_train[t]] = 1\n",
    "\n",
    "        # penilize the ones that do not have\n",
    "        self.Alpha[:, t] -= np.heaviside(-(preds * y), 1) * self.sign(preds)\n",
    "        # for each perceptron\n",
    "        # for cl in range(self.n_classes):\n",
    "        #     # create and save predictions\n",
    "        #     pred = np.inner(self.K[t, :], perceptrons[cl].alpha)\n",
    "        #     confidence[cl] = pred\n",
    "        #\n",
    "        #     y = 1 if y_train[t] == float(cl) else (-1)\n",
    "        #     ## penalize if the prediction wrong\n",
    "        #     if y*pred <= 0:\n",
    "        #         perceptrons[cl].alpha[t] -= self.sign(pred)\n",
    "        return confidence\n",
    "\n",
    "    def fit(self, X_train, y_train, n_epochs):\n",
    "        y_preds = np.array(np.zeros(X_train.shape[0]))\n",
    "\n",
    "        self.K = self._get_kernel_matrix(X_train)\n",
    "        self.Alpha = np.zeros((self.n_classes, X_train.shape[0]))\n",
    "        self.X_train = X_train\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            # for each point, calculate confidence and make predictions\n",
    "            for t in range(0, X_train.shape[0]):\n",
    "                confidence = self._predict_single_confidence(t, y_train)\n",
    "                # the index with the highest number(confidence) is the prediction\n",
    "                # +1 because the index for confidence in perceptron[1] is 0\n",
    "                y_preds[t] = np.argmax(confidence) + 1\n",
    "        return y_preds\n",
    "\n",
    "    def _choose_best_ytest(self, yhats):\n",
    "        # get the classifiers that predicted positive\n",
    "        maxims = np.argwhere(yhats == np.amax(yhats)).flatten() + 1\n",
    "        if maxims.shape[0] == 1:\n",
    "            # if only 1 classifier predicts positive, take that class\n",
    "             return maxims[0]\n",
    "        else:\n",
    "            # if more than one predicted positive, or all of them negative, choose one randomly\n",
    "            return np.random.choice(maxims)\n",
    "\n",
    "    def predict(self, X_test: np.ndarray):\n",
    "        ypreds = np.array(np.zeros(X_test.shape[0]))# *(x, y) => kernel(x, y)\n",
    "        partial_kernels = np.array([partial(self.kernel, X_train)(X_test)])\n",
    "        ## for polynomial kernel\n",
    "        self.K_test = np.power(X_train @ X_test.T, self.d)       #shape (X_test.shape[0], X_train.shape[0])\n",
    "\n",
    "\n",
    "        for t_test in range(X_test.shape[0]):\n",
    "            # yhats_sums = np.array(np.zeros(self.n_classes))\n",
    "            # for cl in range(self.n_classes):\n",
    "            #     # update\n",
    "            #     sum = np.inner(self.Alpha[:, t])\n",
    "            #     for t in range(self.X_train.shape[0]):\n",
    "            #         sum += self.perceptrons[cl].alpha[t] * self.kernel(self.X_train[t], X_test[t_test], self.d)\n",
    "            #     yhats_sums[cl] = sum\n",
    "\n",
    "            yhats_sums = self.Alpha @ self.K_test[t_test]\n",
    "            ypreds[t_test] = self._choose_best_ytest(yhats_sums)\n",
    "        return ypreds\n",
    "\n",
    "\n",
    "### for in-cell debug\n",
    "# kpova = KPOneVsAllClassifier(polynomial_kernel, n_classes=3, d=3)\n",
    "# kpova.fit(X_train, y_train, n_epochs=1)\n",
    "# y_insample = kpova.predict(X_train)\n",
    "# y_outsample = kpova.predict(X_test)\n",
    "#\n",
    "# get_error_percentage(y_train, y_insample, y_test, y_outsample)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 1.27516459e+06,  5.29563896e+04,  4.52716428e+06, ...,\n         7.34842826e+05,  7.27688975e+05,  3.17771279e+06],\n       [ 1.50296007e+05,  6.72671667e+04,  1.26476136e+06, ...,\n         4.60040898e+05,  1.05934857e+05,  1.62002147e+06],\n       [ 1.50912288e+06,  8.94191319e+04,  4.89804523e+06, ...,\n         7.14841827e+05,  8.11351027e+05,  4.11363711e+06],\n       ...,\n       [ 1.57089690e+06,  4.90355094e+05,  9.67786969e+01, ...,\n        -3.83566786e+02,  1.22107783e+05,  3.81519314e+03],\n       [ 1.01414542e+06,  9.56547743e+04,  3.03249680e+06, ...,\n         3.74821378e+05,  5.28312719e+05,  2.60931244e+06],\n       [ 1.20936351e+06,  4.87168232e+04,  8.53799935e+05, ...,\n         5.54821957e+05,  2.06300183e+05,  9.07853478e+05]])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power(X_train @ X_test.T, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took :1764.5372784137726\n",
      "in-sample = % 18.392040871201935\n",
      "out-of-sample = % 21.72043010752688\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "kpova = KPOneVsAllClassifier(polynomial_kernel, n_classes=10, d=3)\n",
    "kpova.fit(X_train, y_train, n_epochs=1)\n",
    "y_insample = kpova.predict(X_train)\n",
    "y_outsample = kpova.predict(X_test)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"took :{t}\".format(t=end-start))\n",
    "\n",
    "get_error_percentage(y_train, y_insample, y_test, y_outsample)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### _Tests_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us test the Kernel Perceptron implementation on a dummy dataset of only digits 1 and 2."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Filter out digit 3 (leave only digit 1 and 2) from dtrain123.dat train and test dataset\n",
    "indxs_digit_3 = np.where(y_train_123 == 3)\n",
    "X_train_12 = np.delete(X_train_123, indxs_digit_3, axis=0)\n",
    "y_train_12 = np.delete(y_train_123, indxs_digit_3)\n",
    "y_train_12[y_train_12 == 1] = -1\n",
    "y_train_12[y_train_12 == 2] = 1\n",
    "\n",
    "indxs_digit_3 = np.where(y_test_123 == 3)\n",
    "X_test_12 = np.delete(X_test_123, indxs_digit_3, axis=0)\n",
    "y_test_12 = np.delete(y_test_123, indxs_digit_3)\n",
    "y_test_12[y_test_12 == 1] = -1\n",
    "y_test_12[y_test_12 == 2] = 1\n",
    "\n",
    "assert X_train_12.shape[0] == y_train_12.size\n",
    "assert X_test_12.shape[0] == y_test_12.size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample = % 0.0\n",
      "out-of-sample = % 1.8518518518518519\n"
     ]
    }
   ],
   "source": [
    "# Test fitting and in-sample predictions\n",
    "kp = KernelPerceptron(kernel=partial(polynomial_kernel, d=5), size=X_train_12.shape[0])\n",
    "y_insample = kp.fit(X_train_12, y_train_12, n_epochs=2)\n",
    "# Test out-of-sample predictions\n",
    "y_outsample = kp.predict(X_test_12) # all predictions of test sample in y_outsample\n",
    "print(\"in-sample = % \" + str(100 * get_num_mistakes(actual=y_train_12, predicted=y_insample) / y_train_12.size))\n",
    "print(\"out-of-sample = % \" + str(100 * get_num_mistakes(actual=y_test_12, predicted=y_outsample) / y_test_12.size))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "KernelPerceptron.__init__() missing 1 required positional argument: 'size'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[69], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m## Test the kernel matrix\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m kp_test \u001B[38;5;241m=\u001B[39m \u001B[43mKernelPerceptron\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkernel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpartial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpolynomial_kernel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43md\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m kernel_matrix \u001B[38;5;241m=\u001B[39m kp_test\u001B[38;5;241m.\u001B[39m_get_kernel_matrix(X_train_12)\n\u001B[0;32m      4\u001B[0m polynomial_kernel(X_train_12[\u001B[38;5;241m0\u001B[39m], X_train_12[\u001B[38;5;241m0\u001B[39m], d\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m) \u001B[38;5;241m==\u001B[39m kernel_matrix[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[1;31mTypeError\u001B[0m: KernelPerceptron.__init__() missing 1 required positional argument: 'size'"
     ]
    }
   ],
   "source": [
    "## Test the kernel matrix\n",
    "kp_test = KernelPerceptron(kernel=partial(polynomial_kernel, d=3))\n",
    "kernel_matrix = kp_test._get_kernel_matrix(X_train_12)\n",
    "polynomial_kernel(X_train_12[0], X_train_12[0], d=3) == kernel_matrix[0][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## *_Part 1_*\n",
    "\n",
    "1. *Basic results*\n",
    "- for $d=1, ... ,7$ perform 20 runs\n",
    "- split $zipcombo$ 80-20\n",
    "- report MSE and STD\n",
    "- yield a 2x7 table that has on each cell $mean+-std$\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "means_train = []\n",
    "means_test = []\n",
    "stds_train = []\n",
    "stds_test = []\n",
    "\n",
    "for d in range(1, 8):\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "    for run in range(20):\n",
    "        X_train, y_train, X_test, y_test = shuffle_split(data)\n",
    "\n",
    "        kpova = KPOneVsAllClassifier(polynomial_kernel, n_classes=10, d=d)\n",
    "\n",
    "        #train\n",
    "        kpova.fit(X_train, y_train, n_epochs=1)\n",
    "        y_insample = kpova.predict(X_train)\n",
    "        #test\n",
    "        y_outsample = kpova.predict(X_test)\n",
    "\n",
    "        train_errors.append(get_error_percentage(y_train, y_insample))\n",
    "        test_errors.append(get_error_percentage(y_test, y_outsample))\n",
    "    means_train.append(np.mean(train_errors))\n",
    "    means_test.append(np.mean(test_errors))\n",
    "    stds_train.append(np.std(train_errors))\n",
    "    stds_test.append(np.std(test_errors))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "pd.DataFrame({\n",
    "    'mean train': [str(x) + u\"\\u00B1\" + str(y) for (x, y) in zip(means_train, stds_train)],\n",
    "    'mean test': [str(x) + u\"\\u00B1\" + str(y) for (x, y) in zip(means_test, stds_test)],\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. _Cross validation_\n",
    "- perform 20 runs\n",
    "- select \"best\" parameter $d*$ using 5-fold cross-validation\n",
    "- retrain on 80% training using $d*$ and record the test errors for 20%\n",
    "- findings: 20 $d*$ and 20 test errors\n",
    "- output: mean_test_error$\\pm$std, mean_$d*\\pm$std"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "possible optimizations:\n",
    "- in predict_single_confidence, try to fill the confidence vector for all perceptrons in 1 numpy operation\n",
    "- in predict_single_confidence, try to compose the y*pred with an np.inner and then go and update the alphas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}